#!/bin/bash
# =============================================================================
# OMO (oh-my-ollama or Ollama Models Organizer)
# =============================================================================
#
# ğŸ¤– åŠŸèƒ½æ¦‚è§ˆï¼š
#   ğŸ“¥ æ¨¡å‹ä¸‹è½½ï¼š
#       â€¢ ä»Ollamaå®˜æ–¹ä»“åº“ä¸‹è½½æ¨¡å‹
#       â€¢ ç›´æ¥ä¸‹è½½HuggingFaceçš„GGUFæ ¼å¼æ¨¡å‹
#
#   ğŸ’¾ æ¨¡å‹å¤‡ä»½ï¼š
#       â€¢ å®Œæ•´å¤‡ä»½Ollamaæ¨¡å‹ï¼ˆmanifest + blobsï¼‰
#       â€¢ MD5æ ¡éªŒç¡®ä¿æ•°æ®å®Œæ•´æ€§
#       â€¢ ç”Ÿæˆè¯¦ç»†å¤‡ä»½ä¿¡æ¯æ–‡ä»¶
#
#   ğŸ”„ æ¨¡å‹æ¢å¤ï¼š
#       â€¢ ä»å¤‡ä»½æ¢å¤Ollamaæ¨¡å‹
#       â€¢ æ”¯æŒå¼ºåˆ¶è¦†ç›–æ¨¡å¼
#       â€¢ è‡ªåŠ¨éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
#
#   ğŸ“‹ æ¨¡å‹ç®¡ç†ï¼š
#       â€¢ åˆ—å‡ºå·²å®‰è£…æ¨¡å‹åŠè¯¦ç»†ä¿¡æ¯
#       â€¢ æ™ºèƒ½åˆ é™¤æ¨¡å‹ï¼ˆå•ä¸ª/æ‰¹é‡ï¼‰
#       â€¢ æ¨¡å‹å®Œæ•´æ€§æ£€æŸ¥å’ŒéªŒè¯
#       â€¢ ç£ç›˜ä½¿ç”¨æƒ…å†µç»Ÿè®¡
#
#   ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²ï¼š
#       â€¢ ç”ŸæˆDocker Composeé…ç½®
#       â€¢ é›†æˆOllamaã€One-APIã€Prompt-Optimizerç­‰æœåŠ¡
#       â€¢ è‡ªåŠ¨GPUæ”¯æŒå’Œæ—¶åŒºé…ç½®
#       â€¢ æ™ºèƒ½ç«¯å£å’Œç½‘ç»œé…ç½®
#
#   âš™ï¸  é«˜çº§ç‰¹æ€§ï¼š
#       â€¢ å¹¶è¡Œå¤„ç†å’Œç¼“å­˜ä¼˜åŒ–
#       â€¢ è¯¦ç»†æ—¥å¿—å’Œé”™è¯¯å¤„ç†
#
# ğŸ“ æ”¯æŒçš„æ¨¡å‹æ ¼å¼ï¼š
#   â€¢ ollama [model]:[tag]     - Ollamaå®˜æ–¹æ¨¡å‹
#   â€¢ hf-gguf [model]:[tag]    - HuggingFace GGUFæ¨¡å‹(ç›´æ¥å¯¼å…¥)
#
# ğŸ”§ ç¯å¢ƒè¦æ±‚ï¼š
#   â€¢ Docker, nvidia gpu, rsync
#
# ğŸ‘¨â€ğŸ’» ä½œè€…ï¼šChain Lai
# ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·è¿è¡Œï¼š./omo.sh --help
# =============================================================================

set -euo pipefail # å¯ç”¨ä¸¥æ ¼çš„é”™è¯¯å¤„ç†

#=============================================
# 1. å…¨å±€é…ç½®å’Œå˜é‡å®šä¹‰ (Global Configuration)
#=============================================
SCRIPT_DIR=""
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]:-$0}")" && pwd)"
readonly SCRIPT_DIR

# åŸºç¡€è·¯å¾„é…ç½®ï¼ˆå¯åœ¨mainå‡½æ•°ä¸­è¢«è¦†ç›–ï¼‰
MODELS_FILE="${SCRIPT_DIR}/models.list"
OLLAMA_DATA_DIR="${SCRIPT_DIR}/ollama" # .ollamaç›®å½•
OLLAMA_MODELS_DIR="${OLLAMA_DATA_DIR}/models"
BACKUP_OUTPUT_DIR="${SCRIPT_DIR}/backups"

# é¢„è®¡ç®—çš„ç»å¯¹è·¯å¾„ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
ABS_OLLAMA_DATA_DIR=""

# Dockeré•œåƒé…ç½®
readonly DOCKER_IMAGE_OLLAMA="ollama/ollama:latest"

# è¿è¡Œæ—¶é…ç½®
VERBOSE="false" # è¯¦ç»†æ¨¡å¼å¼€å…³

# é¢œè‰²å®šä¹‰
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly NC='\033[0m' # No Color

# å…¨å±€ç¼“å­˜å˜é‡
declare -A BACKUP_CONTENT_CACHE

# Ollamaæ¨¡å‹åˆ—è¡¨ç¼“å­˜
declare -g OLLAMA_MODELS_CACHE=""
declare -g OLLAMA_CACHE_INITIALIZED="false"

# ä¸´æ—¶Ollamaå®¹å™¨ç®¡ç†
declare -g TEMP_OLLAMA_CONTAINER=""
declare -g EXISTING_OLLAMA_CONTAINER=""

# å…¨å±€æ¸…ç†å‡½æ•°ç®¡ç†
declare -g GLOBAL_CLEANUP_FUNCTIONS=()
declare -g GLOBAL_CLEANUP_INITIALIZED="false"

#=============================================
# 2. åŸºç¡€å·¥å…·å‡½æ•°æ¨¡å— (Basic Utilities)
#=============================================

get_host_timezone() {
	# å°è¯•å¤šç§æ–¹æ³•è·å–ä¸»æœºæ—¶åŒº
	if command_exists timedatectl; then
		# ä¼˜å…ˆä½¿ç”¨ timedatectlï¼ˆsystemd ç³»ç»Ÿï¼‰
		timedatectl show --property=Timezone --value 2>/dev/null
	elif [[ -L /etc/localtime ]]; then
		# é€šè¿‡ç¬¦å·é“¾æ¥è·å–æ—¶åŒº
		readlink /etc/localtime | sed 's|.*/zoneinfo/||'
	elif [[ -f /etc/timezone ]]; then
		# ä» /etc/timezone æ–‡ä»¶è¯»å–
		cat /etc/timezone
	else
		# é»˜è®¤å›é€€åˆ° UTC
		echo "UTC"
	fi
}

command_exists() {
	command -v "$1" >/dev/null 2>&1
}

#=============================================
# 3. æ—¥å¿—ç³»ç»Ÿæ¨¡å— (Logging System)
#=============================================

log_info() {
	printf "${BLUE}[INFO]${NC} %s\n" "$1"
}

log_success() {
	printf "${GREEN}[SUCCESS]${NC} %s\n" "$1"
}

log_warning() {
	printf "${YELLOW}[WARNING]${NC} %s\n" "$1"
}

log_error() {
	printf "${RED}[ERROR]${NC} %s\n" "$1"
}

# Verbose-only logging functions

log_verbose() {
	if [[ ${VERBOSE} == "true" ]]; then
		printf "${BLUE}[INFO]${NC} %s\n" "$1"
	fi
	return 0
}

log_verbose_success() {
	[[ ${VERBOSE} == "true" ]] && printf "${GREEN}[SUCCESS]${NC} %s\n" "$1"
	return 0
}

log_verbose_warning() {
	[[ ${VERBOSE} == "true" ]] && printf "${YELLOW}[WARNING]${NC} %s\n" "$1"
	return 0
}

#=============================================
# 4. æ–‡ä»¶ç³»ç»Ÿæ“ä½œæ¨¡å— (File System Operations)
#=============================================

# æ–‡ä»¶å¤§å°å·¥å…·å‡½æ•°
format_bytes() {
	local bytes="$1"

	# ä½¿ç”¨å•æ¬¡awkè°ƒç”¨å‡å°‘å¼€é”€ï¼Œé¢„å®šä¹‰å¸¸é‡æé«˜å¯è¯»æ€§
	awk -v b="${bytes}" '
    BEGIN {
        if (b >= 1073741824) printf "%.1fGB", b / 1073741824
        else if (b >= 1048576) printf "%.1fMB", b / 1048576
        else printf "%.1fKB", b / 1024
    }'
}

# è®¡ç®—ç›®å½•çš„MD5æ ¡éªŒå€¼
calculate_directory_md5() {
	local dir_path="$1"
	local md5_file="$2"

	if [[ ! -d ${dir_path} ]]; then
		log_error "Directory does not exist: ${dir_path}"
		return 1
	fi

	log_verbose "Calculating directory MD5 checksum: ${dir_path}"

	# ä½¿ç”¨findå’Œmd5sumè®¡ç®—æ‰€æœ‰æ–‡ä»¶çš„MD5å€¼ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
	# æŒ‰æ–‡ä»¶è·¯å¾„æ’åºä»¥ç¡®ä¿ç»“æœä¸€è‡´æ€§
	if (cd "${dir_path}" && find . -type f -print0 | sort -z | xargs -0 md5sum) >"${md5_file}" 2>/dev/null; then
		log_verbose "MD5 checksum file generated: ${md5_file}"
		return 0
	else
		log_error "Failed to calculate MD5 checksum"
		return 1
	fi
}

# éªŒè¯ç›®å½•çš„MD5æ ¡éªŒå€¼
verify_directory_md5() {
	local dir_path="$1"
	local md5_file="$2"

	# å‚æ•°éªŒè¯
	[[ -d ${dir_path} ]] || {
		log_error "Directory does not exist: ${dir_path}"
		return 1
	}
	[[ -f ${md5_file} ]] || {
		log_error "MD5 checksum file does not exist: ${md5_file}"
		return 1
	}

	log_verbose "Verifying directory MD5 checksum: ${dir_path}"

	# åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¹¶è®¾ç½®è‡ªåŠ¨æ¸…ç†
	local temp_md5
	temp_md5=$(mktemp) || {
		log_error "Unable to create temporary file"
		return 1
	}
	trap "rm -f '${temp_md5}'" RETURN

	# è®¡ç®—å¹¶æ¯”è¾ƒMD5
	calculate_directory_md5 "${dir_path}" "${temp_md5}" || return 1

	if diff "${md5_file}" "${temp_md5}" >/dev/null 2>&1; then
		log_verbose "MD5 checksum verified"
		return 0
	else
		log_error "MD5 checksum verification failed"
		return 1
	fi
}

#=============================================
# 5. è·¯å¾„ç®¡ç†æ¨¡å— (Path Management)
#=============================================

get_model_backup_path() {
	local model_name="$1"
	local model_tag="$2"
	local model_spec="${model_name}:${model_tag}"

	# ç”Ÿæˆå®‰å…¨çš„æ¨¡å‹åç§°
	local model_safe_name
	model_safe_name=$(get_safe_model_name "${model_spec}")

	# è¿”å›å®Œæ•´çš„å¤‡ä»½æ¨¡å‹ç›®å½•è·¯å¾„
	local backup_base_dir="${BACKUP_OUTPUT_DIR}/${model_safe_name}"
	local backup_model_dir="${backup_base_dir}/${model_safe_name}"

	echo "${backup_model_dir}"
}

get_model_manifest_path() {
	local model_name="$1"
	local model_version="$2"

	if [[ ${model_name} == hf.co/* ]]; then
		# HuggingFace GGUFæ¨¡å‹ï¼Œå¦‚ hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF
		echo "${OLLAMA_MODELS_DIR}/manifests/${model_name}/${model_version}"
	elif [[ ${model_name} == *"/"* ]]; then
		# ç”¨æˆ·åˆ†äº«çš„æ¨¡å‹ï¼Œå¦‚ lrs33/bce-embedding-base_v1
		local user_name="${model_name%/*}"
		local repo_name="${model_name#*/}"
		echo "${OLLAMA_MODELS_DIR}/manifests/registry.ollama.ai/${user_name}/${repo_name}/${model_version}"
	else
		# å®˜æ–¹æ¨¡å‹
		echo "${OLLAMA_MODELS_DIR}/manifests/registry.ollama.ai/library/${model_name}/${model_version}"
	fi
}

#=============================================
# 6. Dockerä¸Ollamaç®¡ç†æ¨¡å— (Docker & Ollama)
#=============================================

wait_for_ollama_ready() {
	local container_name="$1"
	local max_attempts=120 # å¢åŠ åˆ°120ç§’
	local attempt=0

	log_verbose "Waiting for Ollama service to start..."

	while ((attempt < max_attempts)); do

		# å¦‚æœå®¹å™¨æ„å¤–å…³é—­
		if ! docker ps -q --filter "name=^${container_name}$" | grep -q .; then
			log_error "Container ${container_name} has stopped running"
			log_error "Container logs:"
			docker logs "${container_name}" 2>&1 | tail -10
			return 1
		fi

		# æ£€æŸ¥ollamaæœåŠ¡æ˜¯å¦å°±ç»ª
		if docker exec "${container_name}" ollama list &>/dev/null; then
			log_verbose_success "Ollama service is ready"
			return 0
		fi

		# æ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
		if ((attempt % 10 == 0 && attempt > 0)); then
			log_verbose "Waiting... (${attempt}/${max_attempts} seconds)"
		fi

		sleep 1
		((attempt++))
	done

	# è¶…æ—¶
	log_error "Timeout waiting for Ollama service to be ready (${max_attempts} seconds)"
	log_error "Container logs:"
	docker logs "${container_name}" 2>&1 | tail -10
	return 1
}

ensure_ollama_image() {
	if ! docker image inspect "${DOCKER_IMAGE_OLLAMA}" &>/dev/null; then
		log_verbose "Pulling ${DOCKER_IMAGE_OLLAMA} image..."
		if ! docker pull "${DOCKER_IMAGE_OLLAMA}"; then
			log_error "${DOCKER_IMAGE_OLLAMA} image pull failed"
			return 1
		fi
		log_verbose_success "${DOCKER_IMAGE_OLLAMA} image pull completed"
	fi
	return 0
}

# æŸ¥æ‰¾è¿è¡Œä¸­çš„Ollamaå®¹å™¨
find_running_ollama_container() {
	# æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­çš„ Ollama å®¹å™¨
	local running_containers
	running_containers=$(docker ps --format "{{.Names}}" --filter "ancestor=ollama/ollama")

	if [[ -n ${running_containers} ]]; then
		# æ‰¾åˆ°ç¬¬ä¸€ä¸ªè¿è¡Œä¸­çš„å®¹å™¨
		EXISTING_OLLAMA_CONTAINER=$(echo "${running_containers}" | head -n1)
		log_verbose "Found running Ollama container: ${EXISTING_OLLAMA_CONTAINER}"
		return 0
	fi

	EXISTING_OLLAMA_CONTAINER=""
	return 1
}

# å¯åŠ¨ä¸´æ—¶Ollamaå®¹å™¨
start_temp_ollama_container() {
	if [[ -n ${TEMP_OLLAMA_CONTAINER} ]]; then
		# æ£€æŸ¥ä¸´æ—¶å®¹å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ
		if docker ps -q --filter "name=^${TEMP_OLLAMA_CONTAINER}$" | grep -q .; then
			log_verbose "Temporary Ollama container still running: ${TEMP_OLLAMA_CONTAINER}"
			return 0
		else
			log_verbose "Temporary Ollama container stopped, restarting"
			TEMP_OLLAMA_CONTAINER=""
		fi
	fi

	# ç¡®ä¿ Ollama é•œåƒå­˜åœ¨
	ensure_ollama_image || return 1

	TEMP_OLLAMA_CONTAINER="ollama-temp-$$"

	log_verbose "Starting temporary Ollama container: ${TEMP_OLLAMA_CONTAINER}"

	# æ„å»ºå®¹å™¨å¯åŠ¨å‘½ä»¤
	local cmd=("docker" "run" "-d" "--name" "${TEMP_OLLAMA_CONTAINER}")
	cmd+=("--gpus" "all")
	cmd+=("-v" "${ABS_OLLAMA_DATA_DIR}:/root/.ollama")
	cmd+=("${DOCKER_IMAGE_OLLAMA}")

	# å¯åŠ¨å®¹å™¨
	local start_output
	if start_output=$("${cmd[@]}" 2>&1); then
		log_verbose "Temporary container started successfully, ID: ${start_output:0:12}"

		# ç­‰å¾…æœåŠ¡å°±ç»ª
		if wait_for_ollama_ready "${TEMP_OLLAMA_CONTAINER}"; then
			log_verbose_success "Temporary Ollama container ready: ${TEMP_OLLAMA_CONTAINER}"
			# è®¾ç½®æ¸…ç†å‡½æ•°
			add_cleanup_function "cleanup_temp_ollama_container"
			return 0
		else
			log_error "Temporary Ollama container startup failed"
			docker rm -f "${TEMP_OLLAMA_CONTAINER}" &>/dev/null
			TEMP_OLLAMA_CONTAINER=""
			return 1
		fi
	else
		log_error "Unable to start temporary Ollama container"
		log_error "Docker startup error: ${start_output}"
		TEMP_OLLAMA_CONTAINER=""
		return 1
	fi
}

execute_ollama_command() {
	local action="$1"
	local with_output="${2:-false}" # æ–°å‚æ•°ï¼šæ˜¯å¦åªè¿”å›è¾“å‡º
	shift 2
	local args=("$@")

	# ä»…åœ¨éè¾“å‡ºæ¨¡å¼ä¸‹æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
	[[ ${with_output} != "true" ]] && log_verbose "Executing Ollama command: ${action} ${args[*]}"

	# ç¡®å®šä½¿ç”¨çš„å®¹å™¨
	local container=""
	if find_running_ollama_container; then
		container="${EXISTING_OLLAMA_CONTAINER}"
		[[ ${with_output} != "true" ]] && log_verbose "Using existing Ollama container: ${container}"
	else
		# å¯åŠ¨ä¸´æ—¶å®¹å™¨
		[[ ${with_output} != "true" ]] && log_verbose "No running Ollama container found, starting temporary container"
		if start_temp_ollama_container; then
			container="${TEMP_OLLAMA_CONTAINER}"
		else
			[[ ${with_output} != "true" ]] && log_error "Unable to start temporary Ollama container"
			return 1
		fi
	fi

	# æ‰§è¡Œå‘½ä»¤
	if [[ ${with_output} == "true" ]]; then
		# åªè¿”å›è¾“å‡ºï¼Œä¸æ˜¾ç¤ºé”™è¯¯
		docker exec "${container}" ollama "${action}" "${args[@]}" 2>/dev/null
	else
		# å®Œæ•´æ‰§è¡Œå¸¦é”™è¯¯å¤„ç†
		[[ ${with_output} != "true" ]] && log_verbose "Executing: docker exec ${container} ollama ${action} ${args[*]}"
		if docker exec "${container}" ollama "${action}" "${args[@]}"; then
			return 0
		else
			log_error "Failed to execute Ollama command: ${action} ${args[*]}"
			return 1
		fi
	fi
}

#=============================================
# 7. æ¨¡å‹å…ƒæ•°æ®ä¸è§£ææ¨¡å— (Model Metadata)
#=============================================

# æ¨¡å‹åç§°å®‰å…¨åŒ–å¤„ç†
# ç»Ÿä¸€çš„æ¨¡å‹åç§°è½¬æ¢å‡½æ•°
# å‚æ•°1: æ¨¡å‹åç§°
# å‚æ•°2: è½¬æ¢ç±»å‹ (backup|ollama|filesystem)
get_safe_model_name() {
	local model_spec="$1"
	local conversion_type="${2:-backup}"

	case "${conversion_type}" in
	"backup")
		# ç”¨äºå¤‡ä»½ç›®å½•å‘½åï¼š/ å’Œ : â†’ _
		echo "${model_spec}" | sed 's/[\/:]/_/g'
		;;
	"ollama")
		# ç”¨äºOllamaæ¨¡å‹å‘½åï¼šå¤æ‚è½¬æ¢è§„åˆ™ï¼ˆä¸€æ¬¡æ€§å¤„ç†ï¼‰
		local full_name_clean
		full_name_clean=$(echo "${model_spec}" | tr '[:upper:]' '[:lower:]' | sed -e 's/\//_/g' -e 's/[^a-z0-9_-]/_/g' -e 's/__*/_/g' -e 's/--*/-/g' -e 's/^[-_]\+\|[-_]\+$//g')
		# é•¿åº¦é™åˆ¶
		if [[ ${#full_name_clean} -gt 50 ]]; then
			local prefix="${full_name_clean:0:30}"
			local suffix="${full_name_clean: -15}"
			full_name_clean="${prefix}_${suffix}"
		fi
		echo "${full_name_clean}"
		;;
	"filesystem")
		# ç”¨äºæ–‡ä»¶ç³»ç»Ÿå®‰å…¨å‘½åï¼š/ â†’ _ï¼Œå…¶ä»–éæ³•å­—ç¬¦ â†’ -
		echo "${model_spec}" | sed -e 's/\//_/g' -e 's/[^a-zA-Z0-9._-]/-/g'
		;;
	*)
		# é»˜è®¤ä½¿ç”¨backupè§„åˆ™
		echo "${model_spec}" | sed 's/[\/:]/_/g'
		;;
	esac
}

# éªŒè¯æ¨¡å‹æ ¼å¼æ˜¯å¦æ­£ç¡®
validate_model_format() {
	local model_spec="$1"
	if [[ ${model_spec} != *":"* ]]; then
		log_error "Invalid model format, should be 'model_name:version', e.g. 'llama2:7b'"
		return 1
	fi
	return 0
}

# è§£ææ¨¡å‹åå­—å’Œç‰ˆæœ¬
parse_model_spec() {
	local model_spec="$1"
	local -n name_var="$2"
	local -n version_var="$3"

	if ! validate_model_format "${model_spec}"; then
		return 1
	fi

	name_var="${model_spec%:*}"
	version_var="${model_spec#*:}"
	return 0
}

# ä»å•ä¸ªmanifestæ–‡ä»¶ä¸­æå–blob digests
extract_blob_digests_from_manifest() {
	local manifest_file="$1"
	local -n digests_ref="$2"

	if [[ ! -f ${manifest_file} ]]; then
		return 1
	fi

	# ä¼˜å…ˆä½¿ç”¨jqè§£æï¼ˆæ›´å¯é ï¼‰ï¼Œå¤‡ç”¨grepæ–¹æ³•
	local blob_digests
	if command -v docker >/dev/null 2>&1 && docker image inspect hf_downloader &>/dev/null; then
		# ä½¿ç”¨Dockerä¸­çš„jqè§£æ
		blob_digests=$(docker run --rm --entrypoint="" -v "$(dirname "${manifest_file}"):/data" hf_downloader jq -r '.layers[].digest, .config.digest' "/data/$(basename "${manifest_file}")" 2>/dev/null | sed 's/sha256://' | sort -u)
	else
		# å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨grepå’Œsedè§£æ
		blob_digests=$(grep -o '"digest":"sha256:[a-f0-9]\{64\}"' "${manifest_file}" 2>/dev/null | sed 's/"digest":"sha256:\([a-f0-9]\{64\}\)"/\1/g')
	fi

	# å°†ç»“æœæ·»åŠ åˆ°æ•°ç»„
	while IFS= read -r digest; do
		[[ -n ${digest} ]] && digests_ref+=("${digest}")
	done <<<"${blob_digests}"
}

parse_manifest_blob_references() {
	local backup_dir="$1"
	local total_blobs_var="$2"  # æ€»å…±æœ‰å‡ ä¸ªblob
	local -n blob_list_ref="$3" # blobsåˆ—è¡¨
	local manifest_path="$4"    # å¯é€‰çš„manifestæ–‡ä»¶è·¯å¾„

	# ç¡®å®šmanifestæ–‡ä»¶åˆ—è¡¨
	local manifest_files=()
	if [[ -n ${manifest_path} ]]; then
		# ä½¿ç”¨æä¾›çš„manifestæ–‡ä»¶è·¯å¾„
		if [[ -f ${manifest_path} ]]; then
			manifest_files+=("${manifest_path}")
		else
			log_error "Specified manifest file not found: ${manifest_path}"
			return 1
		fi
	else
		# ä»manifestsæ–‡ä»¶å¤¹ä¸‹æŸ¥æ‰¾
		while IFS= read -r -d '' manifest; do
			manifest_files+=("${manifest}")
		done < <(find "${backup_dir}" -path "*/manifests/*" -type f -print0 2>/dev/null || true)

		if [[ ${#manifest_files[@]} -eq 0 ]]; then
			log_error "Manifest file not found in backup"
			return 1
		fi
	fi

	# è§£ææ¯ä¸ªmanifestæ–‡ä»¶ä¸­çš„blobå¼•ç”¨
	local total_count=0
	blob_list_ref=()

	for manifest_file in "${manifest_files[@]}"; do
		[[ ! -f ${manifest_file} ]] && continue

		local file_digests=()
		if extract_blob_digests_from_manifest "${manifest_file}" file_digests; then
			for digest in "${file_digests[@]}"; do
				((total_count++))
				blob_list_ref+=("${digest}")
			done
		fi
	done

	eval "${total_blobs_var}=${total_count}"
	return 0
}

# è§£ææ¨¡å‹æ¡ç›®ä¿¡æ¯
parse_model_entry() {
	local model_entry="$1"
	local -n result_ref="$2"

	# æ¸…ç©ºç»“æœæ•°ç»„
	result_ref=()

	if [[ ${model_entry} =~ ^ollama:([^:]+):(.+)$ ]]; then
		result_ref[type]="ollama"
		result_ref[name]="${BASH_REMATCH[1]}"
		result_ref[tag]="${BASH_REMATCH[2]}"
		result_ref[display]="${result_ref[name]}:${result_ref[tag]} (Ollama)"

	elif [[ ${model_entry} =~ ^hf-gguf:(.+)$ ]]; then
		result_ref[type]="hf-gguf"
		local model_full_name="${BASH_REMATCH[1]}"
		if [[ ${model_full_name} =~ ^(.+):(.+)$ ]]; then
			result_ref[name]="${BASH_REMATCH[1]}"
			result_ref[tag]="${BASH_REMATCH[2]}"
		else
			result_ref[name]="${model_full_name}"
			result_ref[tag]="latest"
		fi
		result_ref[display]="${result_ref[name]}:${result_ref[tag]} (HF-GGUF)"
	else
		return 1
	fi

	return 0
}

# ä»æ–‡ä»¶ä¸­è·å–æ¨¡å‹åˆ—è¡¨
parse_models_list() {
	local models_file="$1"
	local -n models_array=${2:-models}

	if [[ ! -f ${models_file} ]]; then
		log_error "Model list file does not exist: ${models_file}"
		return 1
	fi

	log_verbose "Parsing model list file: ${models_file}"

	while IFS= read -r line || [[ -n ${line} ]]; do
		# è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
		[[ -z ${line} || ${line} =~ ^[[:space:]]*# ]] && continue

		# ä½¿ç”¨ç©ºæ ¼åˆ†éš”è§£ææ¨¡å‹ä¿¡æ¯: æ¨¡å‹ç±»å‹ æ¨¡å‹åç§° [é‡åŒ–ç±»å‹]
		read -r model_type model_name quantization <<<"${line}"

		if [[ -n ${model_type} && -n ${model_name} ]]; then
			# æ„å»ºæ¨¡å‹æ¡ç›®å­—ç¬¦ä¸²
			local model_entry
			if [[ -n ${quantization} ]]; then
				model_entry="${model_type}:${model_name}:${quantization}"
			else
				model_entry="${model_type}:${model_name}"
			fi

			# ä½¿ç”¨parse_model_entryéªŒè¯æ¡ç›®æ ¼å¼
			local model_info
			if parse_model_entry "${model_entry}" model_info; then
				models_array+=("${model_entry}")
				log_verbose "Added model: ${model_info[display]}"
			else
				log_warning "Invalid model entry: ${model_entry} (line: ${line})"
			fi
		else
			log_warning "Ignoring invalid line: ${line}"
		fi
	done <"${models_file}"

	# æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æœ‰æ•ˆæ¨¡å‹
	if [[ ${#models_array[@]} -eq 0 ]]; then
		log_warning "================================ WARNING ================================"
		log_warning "No valid models found in models.list file!"
		log_warning "All model entries are either commented out or invalid."
		log_warning ""
		log_warning "Please edit the models.list file:"
		log_warning "1. Uncomment (remove # at the beginning) the models you need"
		log_warning "2. Add your own model configurations"
		log_warning "3. Check model search URLs in the comments for available models"
		log_warning ""
		log_warning "Examples:"
		log_warning "  ollama deepseek-r1:1.5b"
		log_warning "  hf-gguf hf.co/MaziyarPanahi/gemma-3-1b-it-GGUF"
		log_warning "====================================================================="
		echo
	else
		log_verbose "Total models parsed: ${#models_array[@]}"
	fi
}

get_model_blob_paths() {
	local manifest_file="$1"
	local models_dir="$2"
	local blob_paths=()

	if [[ ! -f ${manifest_file} ]]; then
		log_error "Model manifest file does not exist: ${manifest_file}"
		return 1
	fi

	# ä½¿ç”¨ç»Ÿä¸€çš„blob digestæå–å‡½æ•°
	local digests=()
	if ! extract_blob_digests_from_manifest "${manifest_file}" digests; then
		log_error "Failed to extract blob digests from manifest: ${manifest_file}"
		return 1
	fi

	# æ„å»ºblobæ–‡ä»¶è·¯å¾„
	for digest in "${digests[@]}"; do
		# digestå·²ç»ä¸åŒ…å«sha256:å‰ç¼€ï¼Œæ„å»ºsha256-xxxæ ¼å¼çš„æ–‡ä»¶å
		local blob_name="sha256-${digest}"
		local blob_file="${models_dir}/blobs/${blob_name}"
		blob_paths+=("${blob_file}")
	done

	# è¾“å‡ºè·¯å¾„
	printf '%s\n' "${blob_paths[@]}"
}

#=============================================
# 8. ç¼“å­˜ä¸æ¸…ç†ç®¡ç†æ¨¡å— (Cache & Cleanup)
#=============================================

add_cleanup_function() {
	local func_name="$1"
	if [[ -z ${func_name} ]]; then
		log_error "Cleanup function name cannot be empty"
		return 1
	fi

	# æ£€æŸ¥å‡½æ•°æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
	local func
	for func in "${GLOBAL_CLEANUP_FUNCTIONS[@]}"; do
		if [[ ${func} == "${func_name}" ]]; then
			return 0 # å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
		fi
	done

	GLOBAL_CLEANUP_FUNCTIONS+=("${func_name}")

	# å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ·»åŠ ï¼Œè®¾ç½®å…¨å±€ trap
	if [[ ${GLOBAL_CLEANUP_INITIALIZED} == "false" ]]; then
		trap 'execute_global_cleanup' EXIT INT TERM
		GLOBAL_CLEANUP_INITIALIZED="true"
		log_verbose "Initializing global cleanup mechanism"
	fi
}

# æ‰§è¡Œæ‰€æœ‰æ¸…ç†å‡½æ•°
execute_global_cleanup() {
	local exit_code=$?
	local func

	# å¦‚æœæ˜¯ä¸­æ–­ä¿¡å·ï¼Œæ˜¾ç¤ºä¸­æ–­æ¶ˆæ¯
	if [[ ${exit_code} -eq 130 ]]; then # Ctrl+C
		log_warning "Detected interrupt signal (Ctrl+C)"
	elif [[ ${exit_code} -eq 143 ]]; then # SIGTERM
		log_warning "Detected termination signal (SIGTERM)"
	fi

	for func in "${GLOBAL_CLEANUP_FUNCTIONS[@]}"; do
		if declare -f "${func}" >/dev/null 2>&1; then
			log_verbose "Executing cleanup function: ${func}"
			"${func}"
		fi
	done

	# å¦‚æœæ˜¯ä¸­æ–­ï¼Œé€€å‡º
	if [[ ${exit_code} -eq 130 || ${exit_code} -eq 143 ]]; then
		exit "${exit_code}"
	fi
}

# ç§»é™¤æ¸…ç†å‡½æ•°
remove_cleanup_function() {
	local func_name="$1"
	local new_array=()
	local func

	for func in "${GLOBAL_CLEANUP_FUNCTIONS[@]}"; do
		if [[ ${func} != "${func_name}" ]]; then
			new_array+=("${func}")
		fi
	done

	GLOBAL_CLEANUP_FUNCTIONS=("${new_array[@]}")
}

# åˆå§‹åŒ–Ollamaæ¨¡å‹åˆ—è¡¨ç¼“å­˜
init_ollama_cache() {
	if [[ ${OLLAMA_CACHE_INITIALIZED} == "true" ]]; then
		return 0
	fi

	log_verbose "Initializing Ollama model list cache..."

	# ä½¿ç”¨ç»Ÿä¸€çš„å®¹å™¨é€»è¾‘è·å–æ¨¡å‹åˆ—è¡¨
	log_verbose "Getting Ollama model list..."

	# è·å–æ¨¡å‹åˆ—è¡¨å¹¶ç¼“å­˜
	OLLAMA_MODELS_CACHE=$(execute_ollama_command "list" "true" | awk 'NR>1 {print $1}' | sort)
	if [[ -n ${OLLAMA_MODELS_CACHE} ]]; then
		OLLAMA_CACHE_INITIALIZED="true"
		log_verbose_success "Ollama model list cache initialization completed"
	else
		log_verbose "Ollama model list is empty"
		OLLAMA_MODELS_CACHE=""
		OLLAMA_CACHE_INITIALIZED="true"
	fi

	return 0
}

cleanup_temp_ollama_container() {
	if [[ -n ${TEMP_OLLAMA_CONTAINER} ]]; then
		log_verbose "Cleaning up temporary Ollama container: ${TEMP_OLLAMA_CONTAINER}"
		docker rm -f "${TEMP_OLLAMA_CONTAINER}" &>/dev/null
		TEMP_OLLAMA_CONTAINER=""
	fi
}

clear_integrity_cache() {
	[[ -n ${VERBOSE} ]] && log_verbose "Clearing integrity check cache"
	unset BACKUP_CONTENT_CACHE
	declare -g -A BACKUP_CONTENT_CACHE
}

# ç¡®ä¿å®Œæ•´æ€§æ£€æŸ¥ç¼“å­˜å·²åˆå§‹åŒ–
ensure_cache_initialized() {
	# Initialize cache arrays if they do not exist
	if [[ ! -v BACKUP_CONTENT_CACHE ]]; then
		declare -g -A BACKUP_CONTENT_CACHE
		[[ -n ${VERBOSE} ]] && log_verbose "Integrity check cache initialized"
	fi
}

#=============================================
# 9. æ¨¡å‹éªŒè¯æ¨¡å— (Model Validation)
#=============================================

# æ£€æŸ¥HuggingFace GGUFæ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼ˆé€šè¿‡Ollamaæ£€æŸ¥ï¼‰
check_hf_gguf_model() {
	local model_name="$1"
	local model_tag="$2"
	local full_model_name="${model_name}:${model_tag}"

	# ä½¿ç”¨å®¹å™¨æ£€æŸ¥
	if check_ollama_model_exists "${full_model_name}"; then
		log_verbose_success "HuggingFace GGUF model already exists: ${full_model_name}"
		return 0
	fi

	log_verbose_warning "HuggingFace GGUF model does not exist: ${full_model_name}"
	return 1
}

check_model_exists() {
	local -n model_info_ref=$1

	case "${model_info_ref[type]}" in
	"ollama")
		check_ollama_model "${model_info_ref[name]}" "${model_info_ref[tag]}"
		;;
	"hf-gguf")
		check_hf_gguf_model "${model_info_ref[name]}" "${model_info_ref[tag]}"
		;;
	*)
		return 1
		;;
	esac
}

# éªŒè¯Ollamaæ¨¡å‹å®Œæ•´æ€§
validate_ollama_model_integrity() {
	local model_dir="$1"  # æ¨¡å‹ç›®å½•ï¼ˆå¯ä»¥æ˜¯å¤‡ä»½ç›®å½•æˆ–Ollamaæ¨¡å‹ç›®å½•ï¼‰
	local model_spec="$2" # å¯é€‰çš„æ¨¡å‹è§„æ ¼ï¼Œç”¨äºç›´æ¥æ£€æŸ¥å®‰è£…çš„æ¨¡å‹

	local manifest_file=""
	local models_base_dir=""

	if [[ -n ${model_spec} ]]; then
		# æ£€æŸ¥å®‰è£…çš„Ollamaæ¨¡å‹
		local model_name model_version
		model_name="${model_spec%:*}"
		model_version="${model_spec#*:}"
		[[ ${model_version} == "${model_name}" ]] && model_version="latest"

		# è·å–manifestæ–‡ä»¶è·¯å¾„
		manifest_file=$(get_model_manifest_path "${model_name}" "${model_version}")
		models_base_dir="${OLLAMA_MODELS_DIR}"

		# æ£€æŸ¥manifestæ–‡ä»¶æ˜¯å¦å­˜åœ¨
		if [[ ! -f ${manifest_file} ]]; then
			log_error "Model manifest not found: ${model_spec}"
			return 1
		fi
	else
		# æ£€æŸ¥å¤‡ä»½æ¨¡å‹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
		if [[ ! -d ${model_dir} ]]; then
			log_error "Model directory does not exist: ${model_dir}"
			return 1
		fi
		models_base_dir="${model_dir}"
	fi

	# è§£æmanifestæ–‡ä»¶è·å–blobå¼•ç”¨
	local total_blobs=0
	local blob_digests=()
	if [[ -n ${manifest_file} ]]; then
		# ä½¿ç”¨æŒ‡å®šçš„manifestæ–‡ä»¶
		if ! parse_manifest_blob_references "${models_base_dir}" "total_blobs" blob_digests "${manifest_file}"; then
			return 1
		fi
	else
		# ä»å¤‡ä»½ç›®å½•ä¸­æŸ¥æ‰¾manifestæ–‡ä»¶
		if ! parse_manifest_blob_references "${models_base_dir}" "total_blobs" blob_digests; then
			return 1
		fi
	fi

	# æ£€æŸ¥æ¯ä¸ªblobæ–‡ä»¶æ˜¯å¦å­˜åœ¨
	local missing_blobs=0
	for digest in "${blob_digests[@]}"; do
		local blob_path="${models_base_dir}/blobs/sha256-${digest}"
		if [[ ! -f ${blob_path} ]]; then
			log_error "Missing blob file: sha256-${digest}"
			((missing_blobs++))
		fi
	done

	if [[ ${missing_blobs} -gt 0 ]]; then
		log_error "Found ${missing_blobs}/${total_blobs} missing blob files"
		return 1
	fi

	if [[ -n ${model_spec} ]]; then
		log_verbose_success "Ollama model integrity verification passed: ${model_spec} (${total_blobs} blob files)"
	else
		log_verbose_success "Model backup integrity verification passed (${total_blobs} blob files)"
	fi
	return 0
}

# éªŒè¯æ¨¡å‹å®‰è£…åçš„å®Œæ•´æ€§

verify_model_after_installation() {
	local model_name="$1"
	local model_tag="$2"
	local full_model_name="${model_name}:${model_tag}"

	log_verbose "Verifying model installation integrity: ${full_model_name}"

	# åˆå§‹åŒ–ç¼“å­˜ä»¥æé«˜å®Œæ•´æ€§æ£€æŸ¥æ€§èƒ½
	ensure_cache_initialized

	# ç­‰å¾…ä¸€ä¸‹è®©æ–‡ä»¶ç³»ç»ŸåŒæ­¥
	sleep 2

	# æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
	local model_spec="${model_name}:${model_tag}"
	if verify_integrity "model" "${model_spec}" "use_cache:true,check_blobs:true"; then
		log_verbose_success "Model installation integrity verification passed: ${full_model_name}"
		return 0
	else
		log_error "Model installation incomplete, cleaning up: ${full_model_name}"
		cleanup_incomplete_model "${model_name}" "${model_tag}"
		return 1
	fi
}

verify_integrity() {
	local verification_type="$1" # model, backup, hf_model
	local target="$2"            # ç›®æ ‡æ–‡ä»¶/è·¯å¾„/æ¨¡å‹è§„æ ¼
	local options="${3-}"        # é™„åŠ é€‰é¡¹ (use_cache:true, check_blobs:true, etc.)

	# è§£æé€‰é¡¹
	local use_cache="true"
	local check_blobs="true"
	local model_spec=""

	# è§£æé€‰é¡¹å­—ç¬¦ä¸²
	if [[ -n ${options} ]]; then
		while IFS=',' read -ra ADDR; do
			for i in "${ADDR[@]}"; do
				case "${i}" in
				use_cache:*)
					use_cache="${i#*:}"
					;;
				check_blobs:*)
					check_blobs="${i#*:}"
					;;
				model_spec:*)
					model_spec="${i#*:}"
					;;
				*)
					# å¿½ç•¥æœªçŸ¥é€‰é¡¹
					;;
				esac
			done
		done <<<"${options}"
	fi

	# ç¡®ä¿ç¼“å­˜å·²åˆå§‹åŒ–
	[[ ${use_cache} == "true" ]] && ensure_cache_initialized

	# æ ¹æ®éªŒè¯ç±»å‹è°ƒç”¨ç›¸åº”çš„éªŒè¯é€»è¾‘
	case "${verification_type}" in
	"model")
		_verify_local_model "${target}" "${check_blobs}"
		;;
	"backup")
		_verify_backup_target "${target}" "${model_spec}" "${use_cache}" "${check_blobs}"
		;;
	"backup_file")
		_verify_backup_file "${target}" "${use_cache}"
		;;
	*)
		log_error "Unknown verification type: ${verification_type}"
		return 1
		;;
	esac
}

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯æœ¬åœ°æ¨¡å‹å®Œæ•´æ€§

_verify_local_model() {
	local model_spec="$1"
	local check_blobs="$2"

	# è§£ææ¨¡å‹è§„æ ¼
	local model_name model_tag
	if [[ ${model_spec} =~ ^(.+):(.+)$ ]]; then
		model_name="${BASH_REMATCH[1]}"
		model_tag="${BASH_REMATCH[2]}"
	else
		log_error "Invalid model spec format: ${model_spec}"
		return 1
	fi

	# ç¡®å®šmanifestæ–‡ä»¶è·¯å¾„
	local manifest_file
	manifest_file=$(get_model_manifest_path "${model_name}" "${model_tag}")

	# æ£€æŸ¥manifestæ–‡ä»¶æ˜¯å¦å­˜åœ¨
	[[ ! -f ${manifest_file} ]] && return 1

	# å¦‚æœä¸éœ€è¦æ£€æŸ¥blobï¼ŒåªéªŒè¯manifestå­˜åœ¨å³å¯
	[[ ${check_blobs} == "false" ]] && return 0

	# è·å–blobæ–‡ä»¶åˆ—è¡¨å¹¶éªŒè¯
	local blob_files
	blob_files=$(get_model_blob_paths "${manifest_file}" "${OLLAMA_MODELS_DIR}")
	[[ -z ${blob_files} ]] && return 1

	# æ£€æŸ¥æ¯ä¸ªblobæ–‡ä»¶
	while IFS= read -r blob_file; do
		[[ -n ${blob_file} && ! -f ${blob_file} ]] && return 1
	done <<<"${blob_files}"

	return 0
}

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯å¤‡ä»½ç›®æ ‡ï¼ˆç›®å½•å¤‡ä»½ï¼‰

_verify_backup_target() {
	local backup_target="$1"
	local model_spec="$2"
	local use_cache="$3"
	local check_blobs="$4"

	# æ£€æŸ¥ç›®å½•å¤‡ä»½
	if [[ -d ${backup_target} ]]; then
		# Verify directory structure
		if [[ -d "${backup_target}/manifests" ]] && [[ -d "${backup_target}/blobs" ]]; then
			# Verify MD5 checksum
			local md5_file="${backup_target}.md5"
			if [[ -f ${md5_file} ]]; then
				if verify_directory_md5 "${backup_target}" "${md5_file}"; then
					[[ -n ${VERBOSE} ]] && log_info "Directory backup MD5 checksum verified: ${backup_target}"
					return 0
				else
					log_error "Directory backup MD5 checksum failed: ${backup_target}"
					return 1
				fi
			else
				log_warning "MD5 checksum file not found: ${md5_file}"
				return 0 # No MD5 file is still considered valid, but a warning is logged
			fi
		else
			log_error "Invalid directory backup structure: ${backup_target}"
			return 1
		fi
	fi

	return 1
}

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯å¤‡ä»½æ–‡ä»¶ï¼ˆä¸šåŠ¡é€»è¾‘å®Œæ•´æ€§ï¼‰

_verify_backup_file() {
	local backup_dir="$1"
	local use_detailed_check="$2"

	[[ ! -d ${backup_dir} ]] && return 1

	# åŸºæœ¬ç›®å½•ç»“æ„æ£€æŸ¥
	if [[ ! -d ${backup_dir}/manifests ]] || [[ ! -d ${backup_dir}/blobs ]]; then
		return 1
	fi

	# æ£€æŸ¥æ˜¯å¦æœ‰manifestæ–‡ä»¶
	if ! find "${backup_dir}/manifests" -type f -name "*" | head -1 | read -r; then
		return 1
	fi

	# å¦‚æœéœ€è¦è¯¦ç»†æ£€æŸ¥ï¼Œæ‰§è¡Œä¸šåŠ¡é€»è¾‘éªŒè¯
	[[ ${use_detailed_check} == "true" ]] && validate_ollama_model_integrity "${backup_dir}"
}

#=============================================
# 10. æ¨¡å‹ä¸‹è½½æ¨¡å— (Model Download)
#=============================================

download_model() {
	local -n model_info_ref=$1

	case "${model_info_ref[type]}" in
	"ollama" | "hf-gguf")
		download_ollama_model "${model_info_ref[name]}" "${model_info_ref[tag]}"
		;;
	*)
		log_error "Unsupported model type: ${model_info_ref[type]}"
		return 1
		;;
	esac
}

# ä¸‹è½½Ollamaæ¨¡å‹
download_ollama_model() {
	local model_name="$1"
	local model_tag="$2"

	local full_model_name="${model_name}:${model_tag}"

	log_info "Downloading: ${full_model_name}"

	if execute_ollama_command "pull" "false" "${full_model_name}"; then
		log_verbose_success "Downloaded: ${full_model_name}"

		# éªŒè¯ä¸‹è½½åçš„æ¨¡å‹å®Œæ•´æ€§
		if verify_model_after_installation "${model_name}" "${model_tag}"; then
			log_verbose_success "Verified: ${full_model_name}"
			return 0
		else
			log_error "Verification failed: ${full_model_name}"
			return 1
		fi
	else
		log_error "Download failed: ${full_model_name}"
		return 1
	fi
}

# ===== å¤‡ä»½å·¥å…·å‡½æ•° =====

# é€šç”¨å‘½ä»¤æ£€æŸ¥å‡½æ•°

#=============================================
# 11. æ¨¡å‹å¤‡ä»½æ¨¡å— (Model Backup)
#=============================================

backup_ollama_model() {
	local model_name="$1"
	local model_version="$2"

	# åˆå§‹åŒ–ç¼“å­˜ä»¥æé«˜å®Œæ•´æ€§æ£€æŸ¥æ€§èƒ½
	ensure_cache_initialized

	log_verbose "Backing up model: ${model_name}:${model_version}"

	# æ„é€ model_specç”¨äºå®Œæ•´æ€§éªŒè¯
	local model_spec="${model_name}:${model_version}"

	# éªŒè¯æœ¬åœ°æ¨¡å‹å®Œæ•´æ€§
	if ! verify_integrity "model" "${model_spec}" "use_cache:true,check_blobs:true"; then
		log_error "Local model is incomplete, canceling backup operation"
		return 1
	fi

	# è·å–å¤‡ä»½ç›®å½•è·¯å¾„
	local backup_model_dir
	backup_model_dir=$(get_model_backup_path "${model_name}" "${model_version}")

	# æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å¤‡ä»½ç›®å½•
	if [[ -d ${backup_model_dir} ]]; then
		log_success "Model backup already exists"
		return 0
	fi

	# åˆ›å»ºå¤‡ä»½ç›®å½•
	if ! mkdir -p "${backup_model_dir}"; then
		log_error "Unable to create backup directory: ${backup_model_dir}"
		return 1
	fi

	# ç¡®å®šmanifestæ–‡ä»¶è·¯å¾„
	local manifest_file
	manifest_file=$(get_model_manifest_path "${model_name}" "${model_version}")

	# æ£€æŸ¥manifestæ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if [[ ! -f ${manifest_file} ]]; then
		log_error "Model does not exist: ${model_spec}"
		rm -rf "${model_backup_dir}"
		return 1
	fi

	# è·å–blobæ–‡ä»¶è·¯å¾„
	local blob_files
	blob_files=$(get_model_blob_paths "${manifest_file}" "${OLLAMA_MODELS_DIR}")

	if [[ -z ${blob_files} ]]; then
		log_error "No model-related blob files found"
		rm -rf "${model_backup_dir}"
		return 1
	fi

	# åˆ›å»ºå¤‡ä»½ç›®å½•ç»“æ„
	mkdir -p "${backup_model_dir}/manifests" "${backup_model_dir}/blobs"

	log_verbose "Starting file copy..."

	# å¤åˆ¶manifestæ–‡ä»¶
	local manifest_rel_path="${manifest_file#"${OLLAMA_MODELS_DIR}"/manifests/}"
	local manifest_backup_dir="${backup_model_dir}/manifests/$(dirname "${manifest_rel_path}")"
	mkdir -p "${manifest_backup_dir}"
	if ! cp "${manifest_file}" "${manifest_backup_dir}/"; then
		log_error "Failed to copy manifest file: ${manifest_file}"
		rm -rf "${model_backup_dir}"
		return 1
	fi

	# å¤åˆ¶blobæ–‡ä»¶
	while IFS= read -r blob_file; do
		if [[ -f ${blob_file} ]]; then
			if ! cp "${blob_file}" "${backup_model_dir}/blobs/"; then
				log_error "Failed to copy blob file: ${blob_file}"
				rm -rf "${model_backup_dir}"
				return 1
			fi
		fi
	done <<<"${blob_files}"

	# è®¾ç½®å¤‡ä»½ç›®å½•æƒé™ä¸º755
	chmod -R 755 "${backup_model_dir}" || log_warning "Failed to set directory permissions"

	# è®¡ç®—MD5æ ¡éªŒ
	log_verbose "Calculating MD5 checksums..."
	local md5_file="${backup_model_dir}.md5"
	if calculate_directory_md5 "${backup_model_dir}" "${md5_file}"; then
		log_verbose "MD5 checksum file created: ${md5_file}"
		# è®¾ç½®MD5æ–‡ä»¶æƒé™ä¸º644
		chmod 644 "${md5_file}" || log_warning "Failed to set MD5 file permissions"
	else
		log_warning "Failed to create MD5 checksum file"
	fi

	# åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
	create_backup_info "${model_spec}" "${backup_model_dir}" "directory" 1 "ollama"

	log_verbose_success "Model backup completed: ${model_spec}"
	return 0
}
# å¤‡ä»½å•ä¸ªæ¨¡å‹çš„åŒ…è£…å‡½æ•°

backup_single_model() {
	local -n model_info_ref=$1

	case "${model_info_ref[type]}" in
	"ollama" | "hf-gguf")
		backup_ollama_model "${model_info_ref[name]}" "${model_info_ref[tag]}"
		;;
	*)
		log_error "Unsupported model type for backup: ${model_info_ref[type]}"
		return 1
		;;
	esac
}

# è‡ªåŠ¨è¯†åˆ«å¤‡ä»½ç±»å‹å¹¶æ¢å¤
# æ‰¹é‡å¤‡ä»½æ¨¡å‹ï¼ˆæ ¹æ®models.listæ–‡ä»¶ï¼‰

backup_models_from_list() {
	local models_file="$1"

	log_verbose "æ‰¹é‡å¤‡ä»½æ¨¡å‹..."
	log_verbose "æ¨¡å‹åˆ—è¡¨æ–‡ä»¶: ${models_file}"
	log_verbose "å¤‡ä»½ç›®å½•: ${BACKUP_OUTPUT_DIR}"

	# è§£ææ¨¡å‹åˆ—è¡¨
	local models=()
	parse_models_list "${models_file}" models

	if [[ ${#models[@]} -eq 0 ]]; then
		log_warning "æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹è¿›è¡Œå¤‡ä»½"
		return 1
	fi

	# åˆ›å»ºå¤‡ä»½ç›®å½•
	mkdir -p "${BACKUP_OUTPUT_DIR}"

	local total_models=${#models[@]}
	local processed=0
	local success=0
	local failed=0

	log_verbose "å…±æ‰¾åˆ° ${total_models} ä¸ªæ¨¡å‹è¿›è¡Œå¤‡ä»½"

	# é¢„å…ˆåˆå§‹åŒ–Ollamaç¼“å­˜ï¼Œé¿å…æ¯ä¸ªæ¨¡å‹éƒ½é‡æ–°åˆå§‹åŒ–
	local has_ollama_models=false
	for model in "${models[@]}"; do
		if [[ ${model} =~ ^ollama: ]] || [[ ${model} =~ ^hf-gguf: ]]; then
			has_ollama_models=true
			break
		fi
	done

	if [[ ${has_ollama_models} == "true" ]]; then
		log_verbose "æ£€æµ‹åˆ°Ollamaæ¨¡å‹ï¼Œé¢„å…ˆåˆå§‹åŒ–æ¨¡å‹ç¼“å­˜..."
		if ! init_ollama_cache; then
			log_error "Ollamaç¼“å­˜åˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½å½±å“å¤‡ä»½æ€§èƒ½"
		fi
	fi

	for model in "${models[@]}"; do
		((processed++))
		log_info "å¤‡ä»½æ¨¡å‹ [${processed}/${total_models}]: ${model}"

		# è§£ææ¨¡å‹æ¡ç›®
		if [[ ${model} =~ ^ollama:([^:]+):(.+)$ ]]; then
			local model_name="${BASH_REMATCH[1]}"
			local model_tag="${BASH_REMATCH[2]}"

			# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
			if check_ollama_model "${model_name}" "${model_tag}"; then
				if backup_ollama_model "${model_name}" "${model_tag}"; then
					((success++))
				else
					((failed++))
				fi
			else
				((failed++))
			fi

		elif [[ ${model} =~ ^hf-gguf:(.+)$ ]]; then
			local model_full_name="${BASH_REMATCH[1]}"

			# è§£æHuggingFace GGUFæ¨¡å‹åç§°
			if [[ ${model_full_name} =~ ^(.+):(.+)$ ]]; then
				local model_name="${BASH_REMATCH[1]}"
				local model_tag="${BASH_REMATCH[2]}"
			else
				local model_name="${model_full_name}"
				local model_tag="latest"
			fi

			# æ£€æŸ¥HF GGUFæ¨¡å‹æ˜¯å¦å­˜åœ¨
			if check_hf_gguf_model "${model_name}" "${model_tag}"; then
				if backup_ollama_model "${model_name}" "${model_tag}"; then
					((success++))
				else
					((failed++))
				fi
			else
				((failed++))
			fi

		else
			log_error "æ— æ•ˆçš„æ¨¡å‹æ¡ç›®æ ¼å¼: ${model}"
			((failed++))
		fi

		echo "" # æ·»åŠ ç©ºè¡Œåˆ†éš”
	done

	# æ˜¾ç¤ºå¤‡ä»½æ€»ç»“
	log_verbose_success "æ‰¹é‡å¤‡ä»½å®Œæˆ (${success}/${total_models})"
	if [[ ${failed} -gt 0 ]]; then
		log_warning "å¤‡ä»½å¤±è´¥: ${failed}"
		return 1
	fi

	# æ˜¾ç¤ºå¤‡ä»½ç›®å½•ä¿¡æ¯
	if [[ ${VERBOSE} == "true" ]] && [[ -d ${backup_dir} ]]; then
		# åªç»Ÿè®¡é¡¶çº§æ¨¡å‹ç›®å½•ï¼Œæ’é™¤å­ç›®å½•
		local backup_count
		backup_count=$(find "${backup_dir}" -maxdepth 1 -type d ! -path "${backup_dir}" | wc -l)
		local total_size
		total_size=$(du -sh "${backup_dir}" 2>/dev/null | cut -f1)
		log_info "å¤‡ä»½ç›®å½•ä¸‹å…±æœ‰: ${backup_count} ä¸ªæ¨¡å‹ï¼Œæ€»å¤§å°: ${total_size}"
	fi

	# æ¸…ç†å®Œæ•´æ€§æ£€æŸ¥ç¼“å­˜
	clear_integrity_cache

	if [[ ${failed} -eq 0 ]]; then
		log_verbose_success "å…¨éƒ¨æ¨¡å‹å¤‡ä»½å®Œæˆ"
		return 0
	else
		log_warning "éƒ¨åˆ†æ¨¡å‹å¤‡ä»½å¤±è´¥"
		return 1
	fi
}
# åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶

create_backup_info() {
	local model_spec="$1"
	local backup_base="$2"
	local backup_type="$3"   # "directory", "single" æˆ– "split"
	local _volume_count="$4" # Reserved for future use
	local backup_extension="${5:-original}"

	local info_file="${backup_base}_info.txt"
	local current_time
	current_time=$(date '+%Y-%m-%d %H:%M:%S %Z')
	local model_safe_name
	model_safe_name=$(get_safe_model_name "${model_spec}")

	# ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤‡ä»½ä¿¡æ¯
	local temp_info
	temp_info=$(mktemp)
	cat >"${temp_info}" <<EOF
================================================================================
                           æ¨¡å‹å¤‡ä»½ä¿¡æ¯
================================================================================

å¤‡ä»½åŸºæœ¬ä¿¡æ¯:
  æ¨¡å‹è§„æ ¼: ${model_spec}
  å¤‡ä»½åç§°: ${model_safe_name}
  å¤‡ä»½ç±»å‹: ${backup_type}
  åˆ›å»ºæ—¶é—´: ${current_time}

å¤‡ä»½æ–‡ä»¶ä¿¡æ¯:
EOF

	# æ ¹æ®å¤‡ä»½ç±»å‹æ·»åŠ å…·ä½“çš„æ–‡ä»¶ä¿¡æ¯å’ŒMD5
	if [[ ${backup_type} == "directory" ]]; then
		local backup_dir="${backup_base}_${backup_extension}"
		# å¯¹äºollamaå¤‡ä»½ï¼Œbackup_baseå·²ç»æ˜¯å®Œæ•´è·¯å¾„ï¼Œä¸éœ€è¦æ·»åŠ åç¼€
		if [[ ${backup_extension} == "ollama" ]]; then
			backup_dir="${backup_base}"
		fi
		local backup_size="æœªçŸ¥"
		if [[ -d ${backup_dir} ]]; then
			local total_bytes=0
			# ä½¿ç”¨findå’Œlsè®¡ç®—ç›®å½•æ€»å¤§å°
			while IFS= read -r -d '' file; do
				if [[ -f ${file} ]]; then
					local file_size
					file_size=$(ls -l "${file}" 2>/dev/null | awk '{print $5}' || echo "0")
					total_bytes=$((total_bytes + file_size))
				fi
			done < <(find "${backup_dir}" -type f -print0 2>/dev/null || true)

			if [[ ${total_bytes} -gt 0 ]]; then
				backup_size=$(format_bytes "${total_bytes}")
			fi
		fi
		local md5_file="${backup_dir}.md5"
		local md5_status="æœ‰æ•ˆ"

		if [[ ! -f ${md5_file} ]]; then
			md5_status="ç¼ºå¤±"
		fi

		cat >>"${temp_info}" <<EOF
  å¤‡ä»½æ–¹å¼: ç›®å½•å¤åˆ¶
  å¤‡ä»½ç›®å½•: $(basename "${backup_dir}")
  å¤‡ä»½å¤§å°: ${backup_size}
  MD5æ ¡éªŒæ–‡ä»¶: ${md5_status}

æ–‡ä»¶åˆ—è¡¨:
EOF

		# æ·»åŠ æ–‡ä»¶åˆ—è¡¨
		if [[ -d ${backup_dir} ]]; then
			find "${backup_dir}" -type f -exec basename {} \; | sort >>"${temp_info}"
		fi

		cat >>"${temp_info}" <<EOF

MD5æ ¡éªŒä¿¡æ¯:
EOF

		# æ·»åŠ MD5æ ¡éªŒä¿¡æ¯
		if [[ -f ${md5_file} ]]; then
			cat "${md5_file}" >>"${temp_info}"
		else
			{
				echo "  MD5æ ¡éªŒæ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸å­˜åœ¨"
				echo "  æ–‡ä»¶è·¯å¾„: ${md5_file}"
				echo "  å»ºè®®: é‡æ–°è¿è¡Œå¤‡ä»½ä»¥ç”ŸæˆMD5æ ¡éªŒæ–‡ä»¶"
			} >>"${temp_info}"
		fi

		cat >>"${temp_info}" <<EOF

æ¢å¤å‘½ä»¤:
  # ä½¿ç”¨omo.shæ¢å¤
  ./omo.sh --restore "$(basename "${backup_dir}")"
  
  # æ‰‹åŠ¨æ¢å¤ï¼ˆOllamaæ¨¡å‹ï¼‰
  cp -r "$(basename "${backup_dir}")/manifests/"* "\$OLLAMA_MODELS_DIR/manifests/"
  cp "$(basename "${backup_dir}")/blobs/"* "\$OLLAMA_MODELS_DIR/blobs/"
  

EOF
	else
		log_error "ä¸æ”¯æŒçš„å¤‡ä»½ç±»å‹: ${backup_type}"
		rm -f "${temp_info}"
		return 1
	fi

	cat >>"${temp_info}" <<EOF
================================================================================
                               éªŒè¯ä¿¡æ¯
================================================================================

å¤‡ä»½éªŒè¯:
1. æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§:
   - ä½¿ç”¨MD5æ ¡éªŒæ–‡ä»¶éªŒè¯æ¯ä¸ªæ–‡ä»¶çš„å®Œæ•´æ€§
   - md5sum -c $(basename "${backup_dir}.md5")

2. æ£€æŸ¥å¤‡ä»½ç»“æ„:
   - ç¡®ä¿å¤‡ä»½ç›®å½•åŒ…å«å®Œæ•´çš„æ–‡ä»¶ç»“æ„
   - å¯¹äºOllamaæ¨¡å‹: manifests/ å’Œ blobs/ ç›®å½•

å¤‡ä»½ç‰¹æ€§:
   - ç›´æ¥å¤åˆ¶: æå¿«çš„å¤‡ä»½å’Œæ¢å¤é€Ÿåº¦ï¼Œæ— éœ€å‹ç¼©/è§£å‹ç¼©
   - MD5æ ¡éªŒ: ç¡®ä¿æ–‡ä»¶å®Œæ•´æ€§å’Œä¸€è‡´æ€§
   - ç®€åŒ–ç®¡ç†: å¤‡ä»½æ–‡ä»¶å¯ç›´æ¥è®¿é—®å’Œæ£€æŸ¥

ä½¿ç”¨è¯´æ˜:
- æ­¤å¤‡ä»½åŒ…å«æ¨¡å‹çš„å®Œæ•´æ–‡ä»¶ç»“æ„
- æ¢å¤åå¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€é¢å¤–å¤„ç†
- æ”¯æŒå¢é‡å¤‡ä»½å’Œå·®å¼‚æ£€æŸ¥

ç”Ÿæˆæ—¶é—´: ${current_time}
================================================================================
EOF

	# ç›´æ¥å†™å…¥ä¿¡æ¯æ–‡ä»¶
	if mv "${temp_info}" "${info_file}"; then
		# è®¾ç½®å¤‡ä»½ä¿¡æ¯æ–‡ä»¶æƒé™ä¸º644
		chmod 644 "${info_file}" || log_warning "è®¾ç½®å¤‡ä»½ä¿¡æ¯æ–‡ä»¶æƒé™å¤±è´¥"
		log_verbose_success "Backup info file created: $(basename "${info_file}")"
	else
		log_error "Unable to write backup info file: ${info_file}"
		rm -f "${temp_info}"
		return 1
	fi
}

# æ¢å¤æ¨¡å‹çš„ç»Ÿä¸€å…¥å£å‡½æ•°ï¼ˆä»æ–‡ä»¶è·¯å¾„æ¢å¤ï¼‰

remove_incomplete_backup() {
	local backup_base="$1"
	local backup_suffix="${2-}"

	log_verbose "Deleting incomplete backup: ${backup_base}${backup_suffix}"

	# åˆ é™¤ç›®å½•å¤‡ä»½
	local backup_dir="${backup_base}${backup_suffix}"
	if [[ -d ${backup_dir} ]]; then
		rm -rf "${backup_dir}"
		log_verbose "Backup directory deleted: ${backup_dir}"
	fi

	# åˆ é™¤MD5æ ¡éªŒæ–‡ä»¶
	local md5_file="${backup_dir}.md5"
	if [[ -f ${md5_file} ]]; then
		rm -f "${md5_file}"
		log_verbose "MD5 checksum file deleted: ${md5_file}"
	fi

	# åˆ é™¤å¤‡ä»½ä¿¡æ¯æ–‡ä»¶
	local info_file="${backup_base}${backup_suffix}_info.txt"
	if [[ -f ${info_file} ]]; then
		rm -f "${info_file}"
		log_verbose "Backup info file deleted: ${info_file}"
	fi
}

#=============================================
# 12. æ¨¡å‹æ¢å¤æ¨¡å— (Model Restore)
#=============================================

restore_model() {
	local restore_file="$1"
	local force_restore="${2:-false}"

	# å¤„ç†è·¯å¾„è§£æ
	local restore_path="${restore_file}"
	if [[ ${restore_file} != /* ]]; then
		restore_path="${BACKUP_OUTPUT_DIR}/${restore_file}"
	fi

	# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
	if [[ ! -d ${restore_path} ]]; then
		log_error "Backup directory does not exist: ${restore_path}"
		return 1
	fi

	# åˆ†å‘åˆ°å…·ä½“çš„æ¢å¤å®ç°
	_restore_by_type "ollama" "${restore_path}" "${force_restore}"
}

# å°è¯•ä»å¤‡ä»½è‡ªåŠ¨æ¢å¤æ¨¡å‹ï¼ˆä»æ¨¡å‹ä¿¡æ¯æ¢å¤ï¼‰

try_restore_model() {
	local -n model_info_ref=$1

	case "${model_info_ref[type]}" in
	"ollama" | "hf-gguf")
		_auto_restore_from_backup "${model_info_ref[type]}" "${model_info_ref[name]}" "${model_info_ref[tag]}"
		;;
	*)
		log_error "Unsupported model type for restore: ${model_info_ref[type]}"
		return 1
		;;
	esac
}

# å†…éƒ¨å‡½æ•°ï¼šè‡ªåŠ¨æ¢å¤å®ç°

_auto_restore_from_backup() {
	local model_type="$1"
	local model_name="$2"
	local model_tag="$3"
	local model_spec="${model_name}:${model_tag}"

	log_verbose "Checking for model backup: ${model_spec}"

	# è·å–å¤‡ä»½è·¯å¾„
	local backup_model_dir
	backup_model_dir=$(get_model_backup_path "${model_name}" "${model_tag}")

	# æ£€æŸ¥å¤‡ä»½æ˜¯å¦å­˜åœ¨
	if [[ ! -d ${backup_model_dir} ]]; then
		log_verbose "No backup found: ${backup_model_dir}"
		return 1
	fi

	log_verbose_success "Found model backup: ${backup_model_dir}"
	log_verbose "Restoring model from backup..."

	# è°ƒç”¨ç»Ÿä¸€çš„æ¢å¤å®ç°
	if _restore_by_type "${model_type}" "${backup_model_dir}" "true"; then
		log_success "Successfully restored model from backup: ${model_spec}"
		return 0
	else
		log_warning "Failed to restore model from backup"
		return 1
	fi
}

# å†…éƒ¨å‡½æ•°ï¼šæŒ‰ç±»å‹åˆ†å‘æ¢å¤ï¼ˆç»Ÿä¸€æ¥å£ï¼‰

_restore_by_type() {
	local model_type="$1"
	local backup_path="$2"
	local force_restore="${3:-false}"

	case "${model_type}" in
	"ollama" | "hf-gguf")
		_restore_ollama_implementation "${backup_path}" "${force_restore}"
		;;
	*)
		log_error "Unsupported model type for restore: ${model_type}"
		return 1
		;;
	esac
}

# å†…éƒ¨å‡½æ•°ï¼šOllamaæ¨¡å‹æ¢å¤çš„æ ¸å¿ƒå®ç°

_restore_ollama_implementation() {
	local backup_dir="$1"
	local force_restore="${2:-false}"

	log_info "Restoring model: $(basename "${backup_dir}")"

	# éªŒè¯å¤‡ä»½ç»“æ„
	if ! _validate_backup_structure "${backup_dir}"; then
		return 1
	fi

	# æ‰§è¡Œå®Œæ•´æ€§æ ¡éªŒ
	if ! _verify_backup_integrity "${backup_dir}" "${force_restore}"; then
		return 1
	fi

	# æ£€æŸ¥æ–‡ä»¶å†²çª
	if ! _check_restore_conflicts "${backup_dir}" "${force_restore}"; then
		return 1
	fi

	# æ‰§è¡Œæ–‡ä»¶æ¢å¤
	if ! _perform_files_restore "${backup_dir}"; then
		return 1
	fi

	log_verbose_success "Model restore completed"
	return 0
}

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯å¤‡ä»½ç»“æ„

_validate_backup_structure() {
	local backup_dir="$1"

	if [[ ! -d ${backup_dir} ]]; then
		log_error "Backup directory does not exist: ${backup_dir}"
		return 1
	fi

	if [[ ! -d "${backup_dir}/manifests" ]] || [[ ! -d "${backup_dir}/blobs" ]]; then
		log_error "Invalid backup structure: missing manifests or blobs directory"
		return 1
	fi

	return 0
}

# å†…éƒ¨å‡½æ•°ï¼šéªŒè¯å¤‡ä»½å®Œæ•´æ€§

_verify_backup_integrity() {
	local backup_dir="$1"
	local force_restore="$2"

	local md5_file="${backup_dir}.md5"
	if [[ ! -f ${md5_file} ]]; then
		log_warning "Skipping integrity check: MD5 file not found"
		return 0
	fi

	log_info "Verifying backup integrity..."
	if verify_directory_md5 "${backup_dir}" "${md5_file}"; then
		log_verbose_success "MD5 verification passed"
		return 0
	else
		log_error "Backup integrity check failed"
		if [[ ${force_restore} == "true" ]]; then
			log_warning "Force restore mode, continuing..."
			return 0
		else
			return 1
		fi
	fi
}

# å†…éƒ¨å‡½æ•°ï¼šæ£€æŸ¥æ¢å¤å†²çª

_check_restore_conflicts() {
	local backup_dir="$1"
	local force_restore="$2"

	if [[ ${force_restore} == "true" ]]; then
		return 0
	fi

	log_info "Checking for file conflicts..."
	local conflicts_found=false

	for backup_subdir in manifests blobs; do
		if find "${backup_dir}/${backup_subdir}" -type f 2>/dev/null | while read -r backup_file; do
			local rel_path="${backup_file#"${backup_dir}/${backup_subdir}"/}"
			local target_file="${OLLAMA_MODELS_DIR}/${backup_subdir}/${rel_path}"
			if [[ -f ${target_file} ]]; then
				echo "conflict"
				break
			fi
		done | grep -q "conflict"; then
			conflicts_found=true
			break
		fi
	done

	if [[ ${conflicts_found} == "true" ]]; then
		log_error "File conflicts detected, use --force to override"
		return 1
	fi

	return 0
}

# å†…éƒ¨å‡½æ•°ï¼šæ‰§è¡Œæ–‡ä»¶æ¢å¤

_perform_files_restore() {
	local backup_dir="$1"

	# åˆ›å»ºç›®æ ‡ç›®å½•
	if ! mkdir -p "${OLLAMA_MODELS_DIR}/manifests" "${OLLAMA_MODELS_DIR}/blobs"; then
		log_error "Failed to create Ollama directories"
		return 1
	fi

	# æ¢å¤manifestæ–‡ä»¶
	log_verbose "Restoring model manifests..."
	if ! cp -r "${backup_dir}/manifests/"* "${OLLAMA_MODELS_DIR}/manifests/"; then
		log_error "Failed to restore manifest files"
		return 1
	fi

	# æ¢å¤blobæ–‡ä»¶
	log_verbose "Restoring model data..."
	if ! cp "${backup_dir}/blobs/"* "${OLLAMA_MODELS_DIR}/blobs/"; then
		log_error "Failed to restore blob files"
		return 1
	fi

	return 0
}

# æ ¼å¼åŒ–å­—èŠ‚å¤§å°ä¸ºäººç±»å¯è¯»æ ¼å¼

#=============================================
# 13. æ¨¡å‹ç®¡ç†æ“ä½œæ¨¡å— (Model Management)
#=============================================

check_ollama_model_exists() {
	local model_name="$1"

	# ç¡®ä¿ç¼“å­˜å·²åˆå§‹åŒ–
	if ! init_ollama_cache; then
		log_error "Failed to initialize Ollama model cache"
		return 1
	fi

	# åœ¨ç¼“å­˜ä¸­æŸ¥æ‰¾æ¨¡å‹
	if echo "${OLLAMA_MODELS_CACHE}" | grep -q "^${model_name}$"; then
		return 0
	else
		return 1
	fi
}

# æ¸…ç†ä¸å®Œæ•´çš„æ¨¡å‹

cleanup_incomplete_model() {
	local model_name="$1"
	local model_tag="$2"
	local full_model_name="${model_name}:${model_tag}"

	log_verbose_warning "Detected incomplete model, cleaning up: ${full_model_name}"

	# ç¡®å®šmanifestæ–‡ä»¶è·¯å¾„
	local manifest_file
	manifest_file=$(get_model_manifest_path "${model_name}" "${model_tag}")

	# åˆ é™¤manifestæ–‡ä»¶
	if [[ -f ${manifest_file} ]]; then
		if rm -f "${manifest_file}" 2>/dev/null; then
			log_verbose "Deleted incomplete manifest file: ${manifest_file}"
		else
			log_warning "Unable to delete manifest file: ${manifest_file}"
		fi
	fi

	# æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ£€æŸ¥
	OLLAMA_CACHE_INITIALIZED="false"
	OLLAMA_MODELS_CACHE=""

	log_verbose_success "Incomplete model cleanup completed: ${full_model_name}"
}

# ç®€åŒ–çš„æ¨¡å‹æ£€æŸ¥å‡½æ•°

check_ollama_model() {
	local model_name="$1"
	local model_tag="$2"
	local full_model_name="${model_name}:${model_tag}"

	# é¦–å…ˆå°è¯•é€šè¿‡Ollamaå®¹å™¨æ£€æŸ¥ï¼ˆæœ€å‡†ç¡®ï¼‰
	if check_ollama_model_exists "${full_model_name}"; then
		log_verbose_success "Ollama model already exists: ${full_model_name}"
		return 0
	fi

	# å¦‚æœOllamaå®¹å™¨æ£€æŸ¥å¤±è´¥ï¼Œè¿›è¡Œå®Œæ•´æ€§æ£€æŸ¥ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
	local model_spec="${model_name}:${model_tag}"
	if verify_integrity "model" "${model_spec}" "use_cache:true,check_blobs:true"; then
		log_verbose_success "Ollama model exists (filesystem verification): ${full_model_name}"
		return 0
	else
		log_verbose_warning "Ollama model does not exist or is incomplete: ${full_model_name}"
		return 1
	fi
}

# è§£ææ¨¡å‹è§„æ ¼ï¼ˆmodel:versionæ ¼å¼ï¼‰
# shellcheck disable=SC2034  # nameref variables are used by reference

remove_ollama_model() {
	local model_spec="$1"
	local force_delete="${2:-false}"

	if ! validate_model_format "${model_spec}"; then
		return 1
	fi

	log_verbose "Preparing to remove Ollama model: ${model_spec}"

	# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
	local model_name model_version
	if ! parse_model_spec "${model_spec}" model_name model_version; then
		return 1
	fi
	if ! check_ollama_model "${model_name}" "${model_version}"; then
		log_warning "Model does not exist, no need to delete: ${model_spec}"
		return 0
	fi

	# å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ é™¤ï¼Œè¯¢é—®ç”¨æˆ·ç¡®è®¤
	if [[ ${force_delete} != "true" ]]; then
		log_warning "About to delete model: ${model_spec}"
		echo -n "Confirm deletion? [y/N]: "
		read -r confirm
		if [[ ${confirm} != "y" && ${confirm} != "Y" ]]; then
			log_verbose "Delete operation cancelled"
			return 0
		fi
	fi

	if execute_ollama_command "rm" "false" "${model_spec}"; then
		log_verbose_success "Ollama model deleted successfully: ${model_spec}"
		return 0
	else
		log_error "Failed to delete Ollama model: ${model_spec}"
		return 1
	fi
}

# è·å–æ¨¡å‹ç›¸å…³çš„blobæ–‡ä»¶è·¯å¾„

list_installed_models() {
	log_info "æ‰«æå·²å®‰è£…çš„æ¨¡å‹..."

	# åˆå§‹åŒ–ç¼“å­˜ä»¥æé«˜å®Œæ•´æ€§æ£€æŸ¥æ€§èƒ½
	ensure_cache_initialized

	# æ£€æŸ¥Ollamaæ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨
	if [[ ! -d ${OLLAMA_MODELS_DIR} ]]; then
		log_error "Ollamaæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: ${OLLAMA_MODELS_DIR}"
		return 1
	fi

	local manifests_base_dir="${OLLAMA_MODELS_DIR}/manifests"

	# æ£€æŸ¥manifestsåŸºç¡€ç›®å½•æ˜¯å¦å­˜åœ¨
	if [[ ! -d ${manifests_base_dir} ]]; then
		log_warning "æœªå‘ç°å·²å®‰è£…çš„æ¨¡å‹"
		return 0
	fi

	echo ""
	echo "=================================================================================="
	echo "                             å·²å®‰è£…çš„Ollamaæ¨¡å‹"
	echo "=================================================================================="
	echo ""

	local model_count=0
	local total_size=0
	local total_version_count=0

	# é€’å½’æŸ¥æ‰¾æ‰€æœ‰ manifest æ–‡ä»¶
	local manifest_files=()
	while IFS= read -r -d '' manifest_file; do
		manifest_files+=("${manifest_file}")
	done < <(find "${manifests_base_dir}" -type f -print0 2>/dev/null || true)

	# æŒ‰æ¨¡å‹ç»„ç»‡ manifest æ–‡ä»¶
	declare -A model_manifests

	for manifest_file in "${manifest_files[@]}"; do
		# æå–ç›¸å¯¹äº manifests_base_dir çš„è·¯å¾„
		local relative_path="${manifest_file#"${manifests_base_dir}"/}"

		# æ ¹æ®è·¯å¾„ç»“æ„æå–æ¨¡å‹åå’Œç‰ˆæœ¬
		local model_name=""
		local version=""
		local full_model_path=""

		if [[ ${relative_path} =~ ^registry\.ollama\.ai/library/([^/]+)/(.+)$ ]]; then
			# ä¼ ç»Ÿ Ollama æ¨¡å‹: registry.ollama.ai/library/model_name/version
			model_name="${BASH_REMATCH[1]}"
			version="${BASH_REMATCH[2]}"
			full_model_path="registry.ollama.ai/library/${model_name}"
		elif [[ ${relative_path} =~ ^hf\.co/([^/]+)/([^/]+)/(.+)$ ]]; then
			# HF-GGUF æ¨¡å‹: hf.co/user/repo/version
			local user="${BASH_REMATCH[1]}"
			local repo="${BASH_REMATCH[2]}"
			version="${BASH_REMATCH[3]}"
			model_name="hf.co/${user}/${repo}"
			full_model_path="hf.co/${user}/${repo}"
		else
			# å…¶ä»–æœªçŸ¥æ ¼å¼ï¼Œå°è¯•é€šç”¨è§£æ
			local path_parts
			IFS='/' read -ra path_parts <<<"${relative_path}"
			if [[ ${#path_parts[@]} -ge 2 ]]; then
				version="${path_parts[-1]}"
				unset 'path_parts[-1]'
				model_name=$(
					IFS='/'
					echo "${path_parts[*]}"
				)
				full_model_path="${model_name}"
			else
				continue
			fi
		fi

		# å°† manifest æ·»åŠ åˆ°å¯¹åº”æ¨¡å‹ç»„
		if [[ -n ${model_name} && -n ${version} ]]; then
			local key="${model_name}"
			if [[ -z ${model_manifests[${key}]-} ]]; then
				model_manifests[${key}]="${manifest_file}|${version}|${full_model_path}"
			else
				model_manifests[${key}]="${model_manifests[${key}]};;${manifest_file}|${version}|${full_model_path}"
			fi
		fi
	done

	# æ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„ä¿¡æ¯
	for model_name in "${!model_manifests[@]}"; do
		local model_data="${model_manifests[${model_name}]}"

		# è§£æç¬¬ä¸€ä¸ªæ¡ç›®ä»¥è·å–è·¯å¾„ä¿¡æ¯
		local first_entry="${model_data%%;*}"
		local full_model_path="${first_entry##*|}"
		local model_dir="${manifests_base_dir}/${full_model_path}"

		echo "ğŸ“¦ æ¨¡å‹: ${model_name}"
		[[ ${VERBOSE} == "true" ]] && echo "   â”œâ”€ ä½ç½®: ${model_dir}"

		local version_count=0

		# å¤„ç†æ‰€æœ‰ç‰ˆæœ¬
		IFS=';;' read -ra entries <<<"${model_data}"
		for entry in "${entries[@]}"; do
			IFS='|' read -r manifest_file version _ <<<"${entry}"

			if [[ ! -f ${manifest_file} ]]; then
				continue
			fi

			# æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
			local integrity_status=""
			local check_model_spec="${model_name}:${version}"
			if verify_integrity "model" "${check_model_spec}" "use_cache:true,check_blobs:true"; then
				integrity_status=" âœ“(å®Œæ•´)"
			else
				integrity_status=" âš ï¸(ä¸å®Œæ•´)"
			fi

			echo "   â”œâ”€ ç‰ˆæœ¬: ${version}${integrity_status}"

			# è¯»å–manifestæ–‡ä»¶è·å–blobä¿¡æ¯
			if [[ ${VERBOSE} == "true" ]] && [[ -f ${manifest_file} ]]; then
				local manifest_content
				if manifest_content=$(cat "${manifest_file}" 2>/dev/null); then
					# manifestæ˜¯JSONæ ¼å¼ï¼Œè§£æè·å–æ‰€æœ‰å±‚çš„å¤§å°
					local total_model_size=0
					local blob_count=0
					local model_type="æœªçŸ¥"

					# å°è¯•ä»JSONä¸­æå–æ¨¡å‹ç±»å‹
					if echo "${manifest_content}" | grep -q "application/vnd.ollama.image.model"; then
						model_type="Ollamaæ¨¡å‹"
					fi

					# æå–configå¤§å°
					local config_size
					if config_size=$(echo "${manifest_content}" | grep -o '"config":{[^}]*"size":[0-9]*' | grep -o '[0-9]*$' 2>/dev/null); then
						total_model_size=$((total_model_size + config_size))
						blob_count=$((blob_count + 1))
					fi

					# æå–æ‰€æœ‰layersçš„å¤§å°
					local layer_sizes
					if layer_sizes=$(echo "${manifest_content}" | grep -o '"size":[0-9]*' | grep -o '[0-9]*' 2>/dev/null); then
						while IFS= read -r size; do
							if [[ -n ${size} && ${size} -gt 0 ]]; then
								total_model_size=$((total_model_size + size))
								blob_count=$((blob_count + 1))
							fi
						done <<<"${layer_sizes}"
					fi

					# æ ¼å¼åŒ–å¤§å°æ˜¾ç¤º
					local human_size
					human_size=$(format_bytes "${total_model_size}")

					echo "   â”œâ”€ å¤§å°: ${human_size}"

					total_size=$((total_size + total_model_size))
				fi
			fi

			version_count=$((version_count + 1))
		done

		echo "   â””â”€ ç‰ˆæœ¬æ•°é‡: ${version_count}"
		echo ""
		model_count=$((model_count + 1))
		total_version_count=$((total_version_count + version_count))
	done

	# æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
	echo "=================================================================================="
	echo "ç»Ÿè®¡ä¿¡æ¯:"
	echo "  ğŸ“Š æ€»æ¨¡å‹æ•°: ${model_count}"
	echo "  ğŸ”¢ æ€»ç‰ˆæœ¬æ•°: ${total_version_count}"

	# æ ¼å¼åŒ–æ€»å¤§å°
	if [[ ${VERBOSE} == "true" ]]; then
		local total_human_size
		total_human_size=$(format_bytes "${total_size}")
		echo "  ğŸ’¾ å¤§å°: ${total_human_size}"
	fi
	echo "  ğŸ“ ç›®å½•: ${OLLAMA_MODELS_DIR}"

	# æ˜¾ç¤ºç£ç›˜ä½¿ç”¨æƒ…å†µ
	local disk_usage
	if disk_usage=$(du -sh "${OLLAMA_MODELS_DIR}" 2>/dev/null || true); then
		local disk_size
		disk_size=$(echo "${disk_usage}" | cut -f1)
		echo "  ğŸ—„ï¸ Disk usage: ${disk_size}"
	fi

	echo "=================================================================================="
	echo ""

	return 0
}

# å¤‡ä»½Ollamaæ¨¡å‹ï¼ˆç›´æ¥å¤åˆ¶ï¼‰
# æ™ºèƒ½åˆ é™¤æ¨¡å‹ï¼ˆè‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹ï¼‰

remove_model_smart() {
	local model_input="$1"
	local force_delete="${2:-false}"

	log_info "åˆ é™¤æ¨¡å‹: ${model_input}"

	# æ£€æŸ¥è¾“å…¥æ ¼å¼ï¼Œåˆ¤æ–­æ˜¯ä»€ä¹ˆç±»å‹çš„æ¨¡å‹
	if [[ ${model_input} =~ ^([^:]+):(.+)$ ]]; then
		local model_name="${BASH_REMATCH[1]}"
		local model_tag_or_quant="${BASH_REMATCH[2]}"

		# å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯Ollamaæ¨¡å‹ï¼ˆç›´æ¥æ ¼å¼ï¼šmodel:tagï¼‰
		if check_ollama_model "${model_name}" "${model_tag_or_quant}"; then
			if remove_ollama_model "${model_input}" "${force_delete}"; then
				return 0
			else
				return 1
			fi
		fi

		# Model not found
		log_error "Model not found or unsupported format: ${model_input}"
		return 1

	else
		log_error "æ¨¡å‹æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º 'æ¨¡å‹å:ç‰ˆæœ¬' æˆ– 'æ¨¡å‹å:é‡åŒ–ç±»å‹'"
		log_error "ä¾‹å¦‚: 'llama2:7b' æˆ– 'microsoft/DialoGPT-small:q4_0'"
		return 1
	fi
}

# æ£€æµ‹å¤‡ä»½æ–‡ä»¶ç±»å‹

# æ‰¹é‡åˆ é™¤æ¨¡å‹ï¼ˆæ ¹æ®models.listæ–‡ä»¶ï¼‰

remove_models_from_list() {
	local models_file="$1"
	local force_delete="${2:-false}"

	log_verbose "Batch deleting models..."
	log_verbose "Model list file: ${models_file}"
	log_info "Force delete mode: ${force_delete}"

	# è§£ææ¨¡å‹åˆ—è¡¨
	local models=()
	parse_models_list "${models_file}" models

	if [[ ${#models[@]} -eq 0 ]]; then
		log_warning "No models found for deletion"
		return 1
	fi

	local total_models=${#models[@]}
	local processed=0
	local success=0
	local failed=0

	log_verbose "å…±æ‰¾åˆ° ${total_models} ä¸ªæ¨¡å‹è¿›è¡Œåˆ é™¤"

	# å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ é™¤ï¼Œæ˜¾ç¤ºè¦åˆ é™¤çš„æ¨¡å‹åˆ—è¡¨å¹¶è¯·æ±‚ç¡®è®¤
	if [[ ${force_delete} != "true" ]]; then
		log_warning "The following models will be deleted:"
		for model in "${models[@]}"; do
			if [[ ${model} =~ ^ollama:([^:]+):(.+)$ ]]; then
				local model_name="${BASH_REMATCH[1]}"
				local model_tag="${BASH_REMATCH[2]}"
				echo "  - Ollamaæ¨¡å‹: ${model_name}:${model_tag}"
			elif [[ ${model} =~ ^hf-gguf:(.+)$ ]]; then
				local model_full_name="${BASH_REMATCH[1]}"
				echo "  - HuggingFace GGUFæ¨¡å‹: ${model_full_name}"
			fi
		done
		echo ""
		echo -n "Confirm deletion of all these models? [y/N]: "
		read -r confirm
		if [[ ${confirm} != "y" && ${confirm} != "Y" ]]; then
			log_info "Cancelled batch delete operation"
			return 2 # ç‰¹æ®Šé€€å‡ºç è¡¨ç¤ºç”¨æˆ·å–æ¶ˆ
		fi
		echo ""
	fi

	for model in "${models[@]}"; do
		((processed++))
		log_info "Deleting model [${processed}/${total_models}]: ${model}"

		# è§£ææ¨¡å‹æ¡ç›®
		if [[ ${model} =~ ^ollama:([^:]+):(.+)$ ]]; then
			local model_name="${BASH_REMATCH[1]}"
			local model_tag="${BASH_REMATCH[2]}"
			local model_spec="${model_name}:${model_tag}"

			log_verbose "åˆ é™¤Ollamaæ¨¡å‹: ${model_spec}"

			if remove_ollama_model "${model_spec}" "true"; then
				((success++))
				log_verbose_success "Ollamaæ¨¡å‹åˆ é™¤æˆåŠŸ: ${model_spec}"
			else
				((failed++))
				log_error "Ollamaæ¨¡å‹åˆ é™¤å¤±è´¥: ${model_spec}"
			fi

		elif [[ ${model} =~ ^hf-gguf:(.+)$ ]]; then
			local model_full_name="${BASH_REMATCH[1]}"

			# è§£æHuggingFace GGUFæ¨¡å‹åç§°
			if [[ ${model_full_name} =~ ^(.+):(.+)$ ]]; then
				local model_name="${BASH_REMATCH[1]}"
				local model_tag="${BASH_REMATCH[2]}"
			else
				local model_name="${model_full_name}"
				local model_tag="latest"
			fi

			local model_spec="${model_name}:${model_tag}"
			log_verbose "åˆ é™¤HuggingFace GGUFæ¨¡å‹: ${model_spec}"

			if remove_ollama_model "${model_spec}" "true"; then
				((success++))
				log_verbose_success "HuggingFace GGUFæ¨¡å‹åˆ é™¤æˆåŠŸ: ${model_spec}"
			else
				((failed++))
				log_error "HuggingFace GGUFæ¨¡å‹åˆ é™¤å¤±è´¥: ${model_spec}"
			fi

		else
			log_error "æ— æ•ˆçš„æ¨¡å‹æ¡ç›®æ ¼å¼: ${model}"
			((failed++))
		fi

		echo "" # æ·»åŠ ç©ºè¡Œåˆ†éš”
	done

	# æ˜¾ç¤ºåˆ é™¤æ€»ç»“
	log_verbose_success "æ‰¹é‡åˆ é™¤å®Œæˆ (${success}/${total_models})"
	if [[ ${failed} -gt 0 ]]; then
		log_warning "åˆ é™¤å¤±è´¥: ${failed}"
	fi

	if [[ ${failed} -eq 0 ]]; then
		log_verbose_success "å…¨éƒ¨æ¨¡å‹åˆ é™¤å®Œæˆ"
		return 0
	else
		log_warning "éƒ¨åˆ†æ¨¡å‹åˆ é™¤å¤±è´¥"
		return 1
	fi
}

# æ£€æŸ¥Ollamaä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šæ¨¡å‹

# æ£€æŸ¥Ollamaä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šæ¨¡å‹ï¼ˆé€šç”¨å‡½æ•°ï¼‰

# æ£€æŸ¥Ollamaæ¨¡å‹åœ¨backupsç›®å½•ä¸­æ˜¯å¦æœ‰å¤‡ä»½
# å¤„ç†å•ä¸ªæ¨¡å‹

#=============================================
# 14. ç³»ç»Ÿæ£€æŸ¥ä¸åˆå§‹åŒ–æ¨¡å— (System Check)
#=============================================

check_gpu_support() {
	# æ£€æŸ¥æ˜¯å¦æ”¯æŒNVIDIA GPU
	if command_exists nvidia-smi && nvidia-smi &>/dev/null; then
		return 0 # æ”¯æŒGPU
	fi
	return 1 # ä¸æ”¯æŒGPU
}

check_dependencies() {
	local missing_deps=()

	# æ£€æŸ¥ docker
	if ! command_exists docker; then
		missing_deps+=("docker")
		log_error "Docker not installed or not in PATH"
	else
		# æ£€æŸ¥ Docker å®ˆæŠ¤è¿›ç¨‹æ˜¯å¦è¿è¡Œ
		if ! docker info &>/dev/null; then
			log_error "Docker is installed but daemon is not running, please start Docker service"
			return 1
		fi
	fi

	# æ£€æŸ¥ tar
	if ! command_exists tar; then
		missing_deps+=("tar")
		log_error "tar not installed, required for model file packing/unpacking"
	fi

	# å¦‚æœæœ‰ç¼ºå¤±çš„ä¾èµ–ï¼Œç»™å‡ºæç¤ºå¹¶é€€å‡º
	if [[ ${#missing_deps[@]} -gt 0 ]]; then
		log_error "Missing required system dependencies: ${missing_deps[*]}"
		log_error "Please install the missing dependencies and rerun the script"
		return 1
	fi

	# æ£€æŸ¥GPUæ”¯æŒï¼ˆå¿…éœ€é¡¹ï¼‰
	if ! check_gpu_support; then
		log_error "No NVIDIA GPU support detected. This script requires a GPU environment."
		log_error "Please ensure: 1) NVIDIA drivers are installed  2) nvidia-smi tool is installed"
		return 1
	fi

	log_verbose "NVIDIA GPU support detected, GPU acceleration will be enabled"

	# æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼Œé™é»˜è¿”å›
	return 0
}

# è§£ææ¨¡å‹åˆ—è¡¨æ–‡ä»¶

#=============================================
# 15. ä»»åŠ¡æ‰§è¡Œä¸ä¸»ç¨‹åºæ¨¡å— (Main Program)
#=============================================

execute_task() {
	local task_name="$1"
	local task_function="$2"
	shift 2
	local task_args=("$@")

	log_info "Executing ${task_name}..."
	if "${task_function}" "${task_args[@]}"; then
		log_success "${task_name} completed"
		exit 0
	else
		local exit_code=$?
		if [[ ${exit_code} -eq 2 ]]; then
			# ç”¨æˆ·å–æ¶ˆæ“ä½œï¼Œä¸æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
			exit 0
		else
			log_error "${task_name} failed"
			exit 1
		fi
	fi
}

# æ¨¡å‹å¤„ç†å™¨ - è§£ææ¨¡å‹æ¡ç›®å¹¶è¿”å›å¤„ç†å‡½æ•°

show_help() {
	cat <<'EOF'
ğŸ¤– OMO - Oh My Ollama / Ollama Models Organizer

ä½¿ç”¨æ–¹æ³•:
  ./omo.sh [OPTIONS]

é€‰é¡¹:
  --models-file FILE    æŒ‡å®šæ¨¡å‹åˆ—è¡¨æ–‡ä»¶ (é»˜è®¤: ./models.list)
  --ollama-dir DIR      æŒ‡å®šOllamaæ•°æ®ç›®å½• (é»˜è®¤: ./ollama)
  --backup-dir DIR      å¤‡ä»½ç›®å½• (é»˜è®¤: ./backups)
  --install             å®‰è£…/ä¸‹è½½æ¨¡å‹ (è¦†ç›–é»˜è®¤çš„ä»…æ£€æŸ¥è¡Œä¸º)
  --check-only          ä»…æ£€æŸ¥æ¨¡å‹çŠ¶æ€ï¼Œä¸ä¸‹è½½ (é»˜è®¤è¡Œä¸º)
  --force-download      å¼ºåˆ¶é‡æ–°ä¸‹è½½æ‰€æœ‰æ¨¡å‹ (è‡ªåŠ¨å¯ç”¨å®‰è£…æ¨¡å¼)
  --verbose             æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
  --list                åˆ—å‡ºå·²å®‰è£…çš„Ollamaæ¨¡å‹åŠè¯¦ç»†ä¿¡æ¯
  --backup MODEL        å¤‡ä»½æŒ‡å®šæ¨¡å‹ (æ ¼å¼: æ¨¡å‹å:ç‰ˆæœ¬)
  --backup-all          å¤‡ä»½æ‰€æœ‰æ¨¡å‹
  --restore FILE        æ¢å¤æŒ‡å®šå¤‡ä»½æ–‡ä»¶
  --remove MODEL        åˆ é™¤æŒ‡å®šæ¨¡å‹
  --remove-all          åˆ é™¤æ‰€æœ‰æ¨¡å‹
  --force               å¼ºåˆ¶æ“ä½œï¼ˆè·³è¿‡ç¡®è®¤ï¼‰
  --generate-compose    ç”Ÿæˆdocker-compose.yamlæ–‡ä»¶ï¼ˆåŸºäºmodels.listï¼‰
  --help                æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

æ¨¡å‹åˆ—è¡¨æ–‡ä»¶æ ¼å¼:
  ollama deepseek-r1:1.5b
  hf-gguf hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:latest

ä¸‹è½½ç¼“å­˜:
  HuggingFace GGUFæ¨¡å‹ä¸‹è½½æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œç¼“å­˜å¤ç”¨
  æ¯ä¸ªæ¨¡å‹æœ‰ç‹¬ç«‹çš„ç¼“å­˜å­ç›®å½•
  ä¸­æ–­åé‡æ–°è¿è¡Œè„šæœ¬å°†æ¢å¤ä¸‹è½½ï¼Œå®Œæˆåè‡ªåŠ¨ç¼“å­˜

EOF
	cat <<'EOF'

Ollamaæ¨¡å‹å¤‡ä»½:
  æ”¯æŒå®Œæ•´çš„Ollamaæ¨¡å‹å¤‡ä»½å’Œæ¢å¤
  å¤‡ä»½ç›®å½•: ./backups (é»˜è®¤ï¼Œå¯é€šè¿‡--backup-diræŒ‡å®š)
  å¤‡ä»½æ ¼å¼: ç›®å½•å¤åˆ¶ (æ¨¡å‹å/)
  åŒ…å«å†…å®¹: manifestæ–‡ä»¶å’Œæ‰€æœ‰blobæ•°æ®
  è‡ªåŠ¨ç”Ÿæˆ: MD5æ ¡éªŒæ–‡ä»¶å’Œè¯¦ç»†ä¿¡æ¯æ–‡ä»¶
  
å¤‡ä»½ç‰¹æ€§:
  - ç›´æ¥å¤åˆ¶å¤‡ä»½ï¼Œæ— å‹ç¼©å¤„ç†ï¼Œå¤‡ä»½å’Œæ¢å¤é€Ÿåº¦æå¿«
  - MD5æ ¡éªŒç¡®ä¿æ–‡ä»¶å®Œæ•´æ€§
  - æ¯ä¸ªæ¨¡å‹ç‹¬ç«‹æ–‡ä»¶å¤¹ï¼Œä¾¿äºç®¡ç†

ç¤ºä¾‹:
  # æ£€æŸ¥æ¨¡å‹çŠ¶æ€ (é»˜è®¤è¡Œä¸º)
  ./omo.sh
  
  # å®‰è£…/ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹
  ./omo.sh --install
  
  # ä»…æ£€æŸ¥çŠ¶æ€ (åŒé»˜è®¤è¡Œä¸º)
  ./omo.sh --check-only
  
  # åˆ—å‡ºå·²å®‰è£…çš„æ¨¡å‹
  ./omo.sh --list
  
  # å¤‡ä»½æ¨¡å‹
  ./omo.sh --backup tinyllama:latest
  
  # åˆ é™¤æ¨¡å‹
  ./omo.sh --remove llama2:7b --force

EOF
}

# æ£€æŸ¥ä¾èµ–
# æ£€æŸ¥GPUæ”¯æŒ

process_model() {
	local model_entry="$1"
	local force_download="$2"
	local check_only="$3"

	# è§£ææ¨¡å‹æ¡ç›®
	local -A model_info
	if ! parse_model_entry "${model_entry}" model_info; then
		log_error "æ— æ•ˆçš„æ¨¡å‹æ¡ç›®æ ¼å¼: ${model_entry}"
		return 1
	fi

	log_verbose "å¤„ç†æ¨¡å‹: ${model_info[display]}"

	# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
	if [[ ${force_download} != "true" ]] && check_model_exists model_info; then
		log_success "æ¨¡å‹å·²å­˜åœ¨"
		return 0
	fi

	# æ¨¡å‹ä¸å­˜åœ¨æˆ–å¼ºåˆ¶ä¸‹è½½
	if [[ ${check_only} == "true" ]]; then
		log_warning "éœ€è¦ä¸‹è½½: ${model_info[display]}"
		return 0
	fi

	# å°è¯•ä»å¤‡ä»½æ¢å¤
	if try_restore_model model_info; then
		log_success "ä»å¤‡ä»½æ¢å¤æˆåŠŸ"
		# æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ£€æŸ¥
		OLLAMA_CACHE_INITIALIZED="false"
		OLLAMA_MODELS_CACHE=""
		return 0
	fi

	# æ‰§è¡Œä¸‹è½½
	if download_model model_info; then
		log_success "æ¨¡å‹ä¸‹è½½å®Œæˆ"
		# æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ£€æŸ¥
		OLLAMA_CACHE_INITIALIZED="false"
		OLLAMA_MODELS_CACHE=""
		return 0
	else
		log_error "æ¨¡å‹å¤„ç†å¤±è´¥: ${model_info[display]}"
		return 1
	fi
}

# ä¸»å‡½æ•°

main() {
	# è·å–ä¸»æœºæ—¶åŒº
	HOST_TIMEZONE=$(get_host_timezone)

	# æ£€æŸ¥å‚æ•° - æ”¯æŒhelpåœ¨ä»»ä½•ä½ç½®
	for arg in "$@"; do
		if [[ ${arg} == "--help" || ${arg} == "-h" ]]; then
			show_help
			exit 0
		fi
	done

	# é»˜è®¤å€¼
	CHECK_ONLY="true"
	FORCE_DOWNLOAD="false"
	BACKUP_MODEL=""
	BACKUP_ALL="false"
	LIST_MODELS="false"
	RESTORE_FILE=""
	GENERATE_COMPOSE="false"
	FORCE_RESTORE="false"
	REMOVE_MODEL=""
	REMOVE_ALL="false"

	# è§£æå‘½ä»¤è¡Œå‚æ•°
	while [[ $# -gt 0 ]]; do
		case $1 in
		--models-file)
			MODELS_FILE="$2"
			shift 2
			;;
		--ollama-dir)
			# å¤„ç†ç”¨æˆ·æŒ‡å®šçš„Ollamaç›®å½•
			local user_ollama_dir="$2"
			user_ollama_dir="${user_ollama_dir%/}" # ç§»é™¤æœ«å°¾æ–œæ 

			# è®¾ç½®æ•°æ®ç›®å½•å’Œæ¨¡å‹ç›®å½•
			if [[ ${user_ollama_dir} == */models ]]; then
				OLLAMA_MODELS_DIR="${user_ollama_dir}"
				OLLAMA_DATA_DIR="${user_ollama_dir%/models}"
			else
				OLLAMA_DATA_DIR="${user_ollama_dir}"
				OLLAMA_MODELS_DIR="${user_ollama_dir}/models"
			fi
			shift 2
			;;
		--backup)
			BACKUP_MODEL="$2"
			shift 2
			;;
		--backup-all)
			BACKUP_ALL="true"
			shift
			;;
		--list)
			LIST_MODELS="true"
			shift
			;;
		--restore)
			RESTORE_FILE="$2"
			shift 2
			;;
		--remove)
			REMOVE_MODEL="$2"
			shift 2
			;;
		--remove-all)
			REMOVE_ALL="true"
			shift
			;;
		--backup-dir)
			BACKUP_OUTPUT_DIR="$2"
			shift 2
			;;
		--check-only)
			CHECK_ONLY="true"
			shift
			;;
		--install)
			CHECK_ONLY="false"
			shift
			;;
		--force-download)
			FORCE_DOWNLOAD="true"
			CHECK_ONLY="false" # å¼ºåˆ¶ä¸‹è½½æ—¶åº”è¯¥å®é™…æ‰§è¡Œä¸‹è½½
			shift
			;;
		--force)
			FORCE_RESTORE="true"
			shift
			;;
		--verbose)
			VERBOSE="true"
			shift
			;;
		--generate-compose)
			GENERATE_COMPOSE="true"
			shift
			;;
		*)
			log_error "æœªçŸ¥å‚æ•°: $1"
			show_help
			exit 1
			;;
		esac
	done

	# æ˜¾ç¤ºå½“å‰ä»»åŠ¡ï¼ˆç®€åŒ–ï¼‰
	local current_task=""
	if [[ -n ${BACKUP_MODEL} ]]; then
		current_task="Backup model: ${BACKUP_MODEL}"
	elif [[ ${BACKUP_ALL} == "true" ]]; then
		current_task="Batch backup all models"
	elif [[ -n ${RESTORE_FILE} ]]; then
		current_task="Restore model: ${RESTORE_FILE}"
	elif [[ -n ${REMOVE_MODEL} ]]; then
		current_task="Remove model: ${REMOVE_MODEL}"
	elif [[ ${REMOVE_ALL} == "true" ]]; then
		current_task="Batch remove all models"
	elif [[ ${LIST_MODELS} == "true" ]]; then
		current_task="List installed models"
	elif [[ ${GENERATE_COMPOSE} == "true" ]]; then
		current_task="Generate Docker Compose configuration"
	elif [[ ${CHECK_ONLY} == "true" ]]; then
		current_task="Check model status"
	else
		current_task="Install/download models"
	fi

	log_info "ğŸš€ Task: ${current_task}"
	log_verbose "Model list file: ${MODELS_FILE}"
	log_verbose "Ollama directory: ${OLLAMA_MODELS_DIR}"
	[[ -n ${BACKUP_OUTPUT_DIR} ]] && log_verbose "Backup directory: ${BACKUP_OUTPUT_DIR}"

	# åˆå§‹åŒ–è·¯å¾„
	mkdir -p "${OLLAMA_DATA_DIR}" || {
		log_error "Unable to create necessary directories"
		return 1
	}
	ABS_OLLAMA_DATA_DIR="$(realpath "${OLLAMA_DATA_DIR}")"

	# ç¡®ä¿Ollamaç›®å½•å­˜åœ¨
	if [[ ! -d ${OLLAMA_MODELS_DIR} ]]; then
		log_verbose "åˆ›å»ºOllamaæ¨¡å‹ç›®å½•..."
		if ! mkdir -p "${OLLAMA_MODELS_DIR}" 2>/dev/null; then
			log_warning "æ— æ³•åˆ›å»ºOllamaæ¨¡å‹ç›®å½•ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨"
		fi
	fi

	# æ‰§è¡Œç‰¹å®šä»»åŠ¡å¹¶é€€å‡º
	if [[ -n ${BACKUP_MODEL} ]]; then
		# è§£ææ¨¡å‹ä¿¡æ¯
		local -A model_info
		if parse_model_entry "${BACKUP_MODEL}" model_info; then
			execute_task "model backup" backup_single_model model_info
		else
			log_error "Invalid model format: ${BACKUP_MODEL}"
			exit 1
		fi
	elif [[ ${BACKUP_ALL} == "true" ]]; then
		execute_task "batch backup" backup_models_from_list "${MODELS_FILE}"
	elif [[ ${LIST_MODELS} == "true" ]]; then
		execute_task "model list" list_installed_models
	elif [[ ${GENERATE_COMPOSE} == "true" ]]; then
		execute_task "Docker configuration generation" generate_docker_compose
	elif [[ -n ${RESTORE_FILE} ]]; then
		execute_task "model restore" restore_model "${RESTORE_FILE}" "${FORCE_RESTORE}"
	elif [[ -n ${REMOVE_MODEL} ]]; then
		execute_task "model removal" remove_model_smart "${REMOVE_MODEL}" "${FORCE_RESTORE}"
	elif [[ ${REMOVE_ALL} == "true" ]]; then
		execute_task "batch delete" remove_models_from_list "${MODELS_FILE}" "${FORCE_RESTORE}"
	fi

	# æ£€æŸ¥ä¾èµ–
	check_dependencies

	# è§£ææ¨¡å‹åˆ—è¡¨
	local models=()
	parse_models_list "${MODELS_FILE}" models

	if [[ ${#models[@]} -eq 0 ]]; then
		log_warning "æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹ï¼Œé€€å‡º"
		exit 0
	fi

	# HuggingFace GGUF models are downloaded directly through Ollama, no Docker images needed

	# å¤„ç†æ¯ä¸ªæ¨¡å‹
	local total_models=${#models[@]}
	local processed=0
	local failed=0

	for model in "${models[@]}"; do
		processed=$((processed + 1))
		log_verbose "å¤„ç†æ¨¡å‹ [${processed}/${total_models}]: ${model}"

		# å¤„ç†å•ä¸ªæ¨¡å‹é”™è¯¯ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
		if ! process_model "${model}" "${FORCE_DOWNLOAD}" "${CHECK_ONLY}"; then
			failed=$((failed + 1))
		fi
	done

	# æ˜¾ç¤ºæ€»ç»“
	log_info "=== å¤„ç†å®Œæˆ ==="
	log_info "æ€»æ¨¡å‹æ•°: ${total_models}"
	log_info "å·²å¤„ç†: ${processed}"
	if [[ ${failed} -gt 0 ]]; then
		log_warning "å¤±è´¥: ${failed}"
	else
		log_success "å…¨éƒ¨æˆåŠŸå®Œæˆ"
	fi

	if [[ ${CHECK_ONLY} == "true" ]]; then
		log_info "æ£€æŸ¥æ¨¡å¼å®Œæˆï¼Œæœªæ‰§è¡Œå®é™…ä¸‹è½½"
	fi
}

# åªæœ‰åœ¨ç›´æ¥è¿è¡Œè„šæœ¬æ—¶æ‰æ‰§è¡Œmainå‡½æ•°
if [[ ${BASH_SOURCE[0]:-$0} == "${0}" ]]; then
	main "$@"
fi
